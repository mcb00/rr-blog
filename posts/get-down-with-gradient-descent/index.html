<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matt Bowers">
<meta name="dcterms.date" content="2021-01-22">
<meta name="description" content="Get down with the intuition for gradient descent via a fresh analogy, develop the mathematical formulation of the algorithm, and implement it from scratch to train a linear regression model.">

<title>Random Realizations - Get Down with Gradient Descent</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon-wbg.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" defer="" src="https://umami.randomrealizations.com/script.js" data-domains="randomrealizations.com" data-website-id="17844d61-f224-45c0-aa5f-2935c14dd5ac"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Random Realizations">
<meta property="og:description" content="A blog about data science, statistics, machine learning, and the scientific method">
<meta property="og:image" content="https://randomrealizations.com/posts/get-down-with-gradient-descent/opengraph.png">
<meta property="og:site-name" content="Random Realizations">
<meta property="og:image:alt" content="dancer getting down">
<link rel="canonical" href="https://randomrealizations.com/posts/get-down-with-gradient-descent/" />
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Random Realizations</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html" rel="" target="">
 <span class="menu-text">Archive</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-series" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Series</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-series">    
        <li>
    <a class="dropdown-item" href="../../gradient-boosting-series.html" rel="" target="">
 <span class="dropdown-text">Gradient Boosting Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="https://python-bloggers.com/" rel="" target="">
 <span class="dropdown-text">Python-Bloggers</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/mcb00" rel="" title="Matt on Github" class="quarto-navigation-tool px-1" aria-label="Matt on Github"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/mcbwrs" rel="" title="Matt on Twitter" class="quarto-navigation-tool px-1" aria-label="Matt on Twitter"><i class="bi bi-twitter"></i></a>
    <a href="https://www.linkedin.com/in/matt-bowers" rel="" title="Matt on Linkedin" class="quarto-navigation-tool px-1" aria-label="Matt on Linkedin"><i class="bi bi-linkedin"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p>includes/subscribe.html</p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#intuition" id="toc-intuition" class="nav-link active" data-scroll-target="#intuition">Intuition</a>
  <ul class="collapse">
  <li><a href="#determine-which-way-to-go" id="toc-determine-which-way-to-go" class="nav-link" data-scroll-target="#determine-which-way-to-go">Determine which way to go</a></li>
  <li><a href="#take-a-step-in-the-right-direction" id="toc-take-a-step-in-the-right-direction" class="nav-link" data-scroll-target="#take-a-step-in-the-right-direction">Take a step in the right direction</a></li>
  </ul></li>
  <li><a href="#general-formulation" id="toc-general-formulation" class="nav-link" data-scroll-target="#general-formulation">General Formulation</a></li>
  <li><a href="#training-a-linear-regression-model-with-gradient-descent" id="toc-training-a-linear-regression-model-with-gradient-descent" class="nav-link" data-scroll-target="#training-a-linear-regression-model-with-gradient-descent">Training a Linear Regression Model with Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#toy-data" id="toc-toy-data" class="nav-link" data-scroll-target="#toy-data">Toy Data</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  </ul></li>
  <li><a href="#wrapping-up" id="toc-wrapping-up" class="nav-link" data-scroll-target="#wrapping-up">Wrapping Up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Get Down with Gradient Descent</h1>
  <div class="quarto-categories">
    <div class="quarto-category">gradient boosting</div>
  </div>
  </div>

<div>
  <div class="description">
    Get down with the intuition for gradient descent via a fresh analogy, develop the mathematical formulation of the algorithm, and implement it from scratch to train a linear regression model.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Matt Bowers </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 22, 2021</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="gd_get_down.png" title="dancer getting down" class="img-fluid"></p>
<p>Ahh, gradient descent. It’s probably one of the most ubiquitous algorithms used in data science, but you’re unlikely to see it being celebrated in the limelight of the Kaggle podium. Rather than taking center stage, gradient descent operates under the hood, powering the training for a wide range of models including deep neural networks, gradient boosting trees, generalized linear models, and mixed effects models. Getting an intuition for the algorithm will reveal how model fitting actually works and help us to see the common thread connecting a wide range of seemingly unrelated models. In this post we’ll get the intuition for gradient descent with a <em>fresh</em> analogy, develop the mathematical formulation, and ground our understanding by using it to train ourselves a linear regression model.</p>
<section id="intuition" class="level2">
<h2 class="anchored" data-anchor-id="intuition">Intuition</h2>
<p>Before we dive into the intuition for gradient descent itself, let’s get a high-level view of why it’s useful in <em>training</em> or <em>fiting</em> a model. Training a model basically means finding the model parameter values that make the model fit a given dataset well. We measure how well a model fits data using a special function variously called a <em>loss</em> or <em>cost</em> or <em>objective</em> function. A loss function takes the dataset and the model as arguments and returns a number that tells us how well our model fits the data. Therefore training is an optimization problem in which we search for the model parameter values that result in the minimum value of the loss function. Enter <em>gradient descent</em>.</p>
<p>Gradient descent is a numerical optimization technique that helps us find the inputs that yield the minimum value of a function. Since most explanations of the gradient descent algorithm seem to use a story about hikers being lost in some foggy mountains, we’re going to try out a new analogy.</p>
<p>Let’s say you’re at a concert. Remember those? They’re these things that used to happen where people played music and everyone danced and had a great time.</p>
<blockquote class="blockquote">
<p><strong><em>NOTE:</em></strong> Chiming in here in 2023 from a sort-of-post COVID 19 world, happily I can report that concerts and live music are back!</p>
</blockquote>
<p>Now suppose at this concert there’s a dance floor which has become a bit sweltering from copious amounts of “getting down”. But the temperature isn’t quite uniform; maybe there’s a cool spot from a ceiling fan somewhere.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gd_dance_floor.png" title="dance floor" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dance floor</figcaption>
</figure>
</div>
<p>Let’s get ourselves to that cool spot using the following procedure.</p>
<ol type="1">
<li>From our current location, figure out which direction feels coolest.</li>
<li>Take a step (or simply shimmy) in that direction.</li>
<li>Repeat steps 1 and 2 until we reach the coolest spot on the dance floor.</li>
</ol>
<p>The crux of this procedure is figuring out, at each step, which direction yields the greatest temperature reduction. Our skin is pretty sensitive to temperature, so we can just use awareness of body sensation to sense which direction feels coolest. Luckily, we have a mathematical equivalent to our skin’s ability to sense local variation in temperature.</p>
<section id="determine-which-way-to-go" class="level3">
<h3 class="anchored" data-anchor-id="determine-which-way-to-go">Determine which way to go</h3>
<p>Let <span class="math inline">\(f(x,y)\)</span> be the temperature on the dance floor at position <span class="math inline">\((x,y)\)</span>. The direction of fastest decrease in temperature is going to be given by some vector in our <span class="math inline">\((x,y)\)</span> space, e.g.,</p>
<p>[vector component in <span class="math inline">\(x\)</span> direction, vector component in <span class="math inline">\(y\)</span> direction]</p>
<p>Turns out that the gradient of a function evaluated at a particular location yields a vector that points in the direction of fastest <em>increase</em> in the function, pretty similar to what we’re looking for. The gradient of <span class="math inline">\(f(x,y)\)</span> is given by</p>
<p><span class="math display">\[ \nabla f(x,y) = \left [ \frac{\partial f(x,y)}{\partial x}, \frac{\partial f(x,y)}{\partial y} \right ] \]</span></p>
<p>The components of the gradient vector are the partial derivatives of our function <span class="math inline">\(f(x,y)\)</span>, evaluated at the point <span class="math inline">\((x,y)\)</span>. These partial derivatives just tell us the slope of <span class="math inline">\(f(x,y)\)</span> in the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> directions respectively. The intuition is that if <span class="math inline">\(\frac{\partial f(x,y)}{\partial x}\)</span> is a large positive number, then moving in the positive <span class="math inline">\(x\)</span> direction will make <span class="math inline">\(f(x,y)\)</span> increase a lot, whereas if <span class="math inline">\(\frac{\partial f(x,y)}{\partial x}\)</span> is a large negative number, then moving in the <em>negative</em> <span class="math inline">\(x\)</span> direction will make <span class="math inline">\(f(x,y)\)</span> increase a lot.</p>
<p>It’s not too hard to see that the direction of fastest decrease is actually just the exact opposite direction from that of fastest increase. Since we can point a vector in the opposite direction by negating its component values, our direction of fastest temperature decrease will be given by the negative gradient of the temperature field <span class="math inline">\(-\nabla f(x,y)\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gd_local_change.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dance floor with hot and cold sides</figcaption>
</figure>
</div>
</section>
<section id="take-a-step-in-the-right-direction" class="level3">
<h3 class="anchored" data-anchor-id="take-a-step-in-the-right-direction">Take a step in the right direction</h3>
<p>Now that we have our direction vector, we’re ready to take a step toward the cool part of the dance floor. To do this, we’ll just add our direction vector to our current position. The update rule would look like this.</p>
<p><span class="math display">\[ [x_\text{next}, y_\text{next}] = [x_\text{prev}, y_\text{prev}] - \nabla f (x_\text{prev}, y_\text{prev}) = [x_\text{prev}, y_\text{prev}] -  \left [ \frac{\partial f (x_\text{prev}, y_\text{prev})}{\partial x}, \frac{\partial f (x_\text{prev}, y_\text{prev})}{\partial y} \right ] \]</span></p>
<p>If we iteratively apply this update rule, we’ll end up tracing a trajectory through the <span class="math inline">\((x,y)\)</span> space on the dance floor and we’ll eventually end up at the coolest spot!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gd_trajectory.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">dance floor with trajectory from hot side to cool side</figcaption>
</figure>
</div>
<p>Great success!</p>
</section>
</section>
<section id="general-formulation" class="level2">
<h2 class="anchored" data-anchor-id="general-formulation">General Formulation</h2>
<p>Let’s generalize a bit to get to the form of gradient descent you’ll see in references like <a href="https://en.wikipedia.org/wiki/Gradient_descent">the wikipedia article</a>.</p>
<p>First we modify our update equation above to handle functions with more than two arguments. We’ll use a bold <span class="math inline">\(\mathbf{x}\)</span> to indicate a vector of inputs <span class="math inline">\(\mathbf{x} = [x_1,x_2,\dots,x_p]\)</span>. Our function <span class="math inline">\(f(\mathbf{x}): \mathbb{R}^p \mapsto \mathbb{R}\)</span> maps a <span class="math inline">\(p\)</span> dimensional input to a scalar output.</p>
<p>Second, instead of displacing our current location with the negative gradient vector itself, we’ll first rescale it with a learning rate parameter. This helps address any issues with units on inputs versus outputs. Imagine the input could range between 0 and 1, but the output ranged from 0 to 1,000. We would need to rescale the partial derivatives so the update step doesn’t send us way too far off in input space.</p>
<p>Finally, we’ll index our updates with <span class="math inline">\(t=0,1,\dots\)</span>. We’ll run for some prespecified number of iterations or we’ll stop the procedure once the change in <span class="math inline">\(f(\mathbf{x})\)</span> is sufficiently small from one iteration to the next. Our update equation will look like this.</p>
<p><span class="math display">\[\mathbf{x}_{t+1} = \mathbf{x}_t - \eta \nabla f ( \mathbf{x}_t) \]</span></p>
<p>In pseudocode we could write it like this.</p>
<pre><code># gradient descent
x = initial_value_of_x 
for t in range(n_iterations):  # or some other convergence condition
    x -= learning_rate * gradient_of_f(x)</code></pre>
<p>Now let’s see how this algorithm gets used to train models.</p>
</section>
<section id="training-a-linear-regression-model-with-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="training-a-linear-regression-model-with-gradient-descent">Training a Linear Regression Model with Gradient Descent</h2>
<p>To get the intuition for how we use gradient descent to train models, let’s use it to train a linear regression model. Note that we wouldn’t actually use gradient descent to train a linear model in real life since there is an exact <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">analytical solution</a> for the best-fit parameter values.</p>
<p>Anyway, in the simple linear regression problem we have numerical feature <span class="math inline">\(x\)</span> and numerical target <span class="math inline">\(y\)</span>, and we want to find a model of the form</p>
<p><span class="math display">\[F(x) = \alpha + \beta x\]</span></p>
<p>This model has two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Here “training” means finding the parameter values that make <span class="math inline">\(F(x)\)</span> fit our <span class="math inline">\(y\)</span> data best. We measure how well, or really how poorly, our model fits the data by using a <em>loss function</em> that yields a small value when a model fits well. Ordinary least squares is so named because it uses mean squared error as its loss function.</p>
<p><span class="math display">\[L(y, F(x)) =  \frac{1}{n} \sum_{i=1}^{n} (y_i - F(x_i))^2  =  \frac{1}{n} \sum_{i=1}^{n} (y_i - (\alpha + \beta x_i))^2 \]</span></p>
<p>The loss function <span class="math inline">\(L\)</span> takes four arguments: <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\beta\)</span>. But since <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are fixed given our dataset, we could write the loss as <span class="math inline">\(L(\alpha, \beta | x, y)\)</span> to emphasize that <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are the only free parameters. So we’re looking for the following.</p>
<p><span class="math display">\[\underset{\alpha,\beta}{\operatorname{argmin}} ~ L(\alpha,\beta|x,y) \]</span></p>
<p>That’s right, we’re looking for the values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> that minimize scalar-valued function <span class="math inline">\(L(\alpha, \beta)\)</span>. Sounds familiar huh?</p>
<p>To solve this minimization problem with gradient descent, we can use the following update rule.</p>
<p><span class="math display">\[[\alpha_{t+1}, \beta_{t+1}] = [\alpha_{t}, \beta_{t}] - \eta \nabla L(\alpha_t, \beta_t | x, y) \]</span></p>
<p>To get the gradient <span class="math inline">\(\nabla L(\alpha,\beta|x,y)\)</span>, we need the partial derivatives of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Since <span class="math inline">\(L\)</span> is just a big sum, it’s easy to calculate the derivatives.</p>
<p><span class="math display">\[ \frac{\partial L(\alpha, \beta)}{\partial \alpha} = \frac{1}{n} \sum_{i=1}^{n} -2 (y_i - (\alpha + \beta x_i)) \]</span> <span class="math display">\[ \frac{\partial L(\alpha, \beta)}{\partial \beta} = \frac{1}{n} \sum_{i=1}^{n} -2x_i (y_i - (\alpha + \beta x_i)) \]</span></p>
<p>Great! We’ve got everything we need to implement gradient descent to train an ordinary least squares model. Everything except data that is.</p>
<section id="toy-data" class="level3">
<h3 class="anchored" data-anchor-id="toy-data">Toy Data</h3>
<p>Let’s make a friendly little linear dataset where <span class="math inline">\(\alpha=-10\)</span> and <span class="math inline">\(\beta=2\)</span>, i.e.</p>
<p><span class="math display">\[ y = -10 + 2x + \text{noise}\]</span></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>alpha_true <span class="op">=</span> <span class="op">-</span><span class="dv">10</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>beta_true <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">42</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">50</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> alpha_true <span class="op">+</span> beta_true<span class="op">*</span>x <span class="op">+</span> rng.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>x.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="get-down_files/figure-html/cell-4-output-1.png" class="img-fluid" alt="Figure showing a scatterplot of x and y data with y increasing linearly in x"></p>
</div>
</div>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>Our implementation will use a function to compute the gradient of the loss function. Since we have two parameters, we’ll use length-2 arrays to hold their values and their partial derivatives. At each iteration, we update the parameter values by subtracting the rescaled partial derivatives.</p>
<div class="cell" data-scrolled="true" data-execution_count="13">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># linear regression using gradient descent </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_of_loss(parameters, x, y):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> parameters[<span class="dv">0</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> parameters[<span class="dv">1</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    partial_alpha <span class="op">=</span> np.mean(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>(y <span class="op">-</span> (alpha <span class="op">+</span> beta<span class="op">*</span>x)))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    partial_beta <span class="op">=</span> np.mean(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x<span class="op">*</span>(y <span class="op">-</span> (alpha <span class="op">+</span> beta<span class="op">*</span>x)))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([partial_alpha, partial_beta])</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>]) <span class="co"># initial values of alpha and beta</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    partial_derivatives <span class="op">=</span> gradient_of_loss(parameters, x, y)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    parameters <span class="op">-=</span> learning_rate <span class="op">*</span> partial_derivatives</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>parameters</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>array([-10.07049616,   2.03559051])</code></pre>
</div>
</div>
<p>We can see the loss function decreasing throughout the 500 iterations.</p>
<div class="cell" data-scrolled="true" data-execution_count="15">
<div class="cell-output cell-output-display">
<p><img src="get-down_files/figure-html/cell-7-output-1.png" class="img-fluid" alt="Figure showing the loss function decreasing with each iteration"></p>
</div>
</div>
<p>And we can visualize the loss function as a contour plot over <span class="math inline">\((\alpha,\beta)\)</span> space. The blue points show the trajectory our gradient descent followed as it shimmied from the initial position to the coolest spot in <span class="math inline">\((\alpha, \beta)\)</span> space where the loss function is nice and small.</p>
<div class="cell" data-scrolled="true" data-execution_count="16">
<div class="cell-output cell-output-display">
<p><img src="get-down_files/figure-html/cell-8-output-1.png" class="img-fluid" alt="Figure showing contour plot of the loss function and a trace moving toward the minimum"></p>
</div>
</div>
<p>Our gradient descent settles in a spot pretty close to <span class="math inline">\((-10, 2)\)</span> in <span class="math inline">\((\alpha,\beta)\)</span> space, which gives us the final fitted model below.</p>
<div class="cell" data-scrolled="true" data-execution_count="18">
<div class="cell-output cell-output-display">
<p><img src="get-down_files/figure-html/cell-10-output-1.png" class="img-fluid" alt="Figure showing the original x and y data along with our fitted line"></p>
</div>
</div>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>There you have it, gradient descent explained with a fresh new analogy having nothing whatsoever to do with foggy mountains, plus an implemented example fitting a linear model. While we often see gradient descent used to train models by performing an optimization in parameter space, as in generalized linear models and neural networks, there are other ways to use this powerful technique to train models. In particular, we’ll soon see how our beloved gradient boosting tree models use gradient descent in <em>prediction space</em>, rather than parameter space. Stay tuned for that mind bender in a future post.</p>


</section>

</main> <!-- /main -->
<hr>

<!-- <div style="max-width: 80%;"> -->
<h3>Comments</h3>
<script data-isso="https://isso.randomrealizations.com/" src="https://isso.randomrealizations.com/js/embed.min.js">
</script>
<section id="isso-thread"></section>
<!-- </div> -->

<hr>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>