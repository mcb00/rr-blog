<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matt Bowers">
<meta name="dcterms.date" content="2022-05-07">
<meta name="description" content="A walkthrough of my from-scratch python implementation of XGBoost.">

<title>Random Realizations – XGBoost from Scratch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon-wbg.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" defer="" src="https://umami.randomrealizations.com/script.js" data-domains="randomrealizations.com" data-website-id="17844d61-f224-45c0-aa5f-2935c14dd5ac"></script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Random Realizations">
<meta property="og:description" content="A blog about data science, statistics, machine learning, and the scientific method">
<meta property="og:image" content="https://randomrealizations.com/posts/xgboost-from-scratch/opengraph.png">
<meta property="og:site-name" content="Random Realizations">
<meta property="og:image:alt" content="A weathered tree reaches toward the sea at Playa Mal País">
<link rel="canonical" href="https://randomrealizations.com/posts/xgboost-from-scratch/" />
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Random Realizations</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html" rel="" target="">
 <span class="menu-text">Archive</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-series" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Series</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-series">    
        <li>
    <a class="dropdown-item" href="../../gradient-boosting-series.html" rel="" target="">
 <span class="dropdown-text">Gradient Boosting Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="https://python-bloggers.com/" rel="" target="">
 <span class="dropdown-text">Python-Bloggers</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/mcb00" rel="" title="Matt on Github" class="quarto-navigation-tool px-1" aria-label="Matt on Github"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/mcbwrs" rel="" title="Matt on Twitter" class="quarto-navigation-tool px-1" aria-label="Matt on Twitter"><i class="bi bi-twitter"></i></a>
    <a href="https://www.linkedin.com/in/matt-bowers" rel="" title="Matt on Linkedin" class="quarto-navigation-tool px-1" aria-label="Matt on Linkedin"><i class="bi bi-linkedin"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<h5 style="font-weight:600; font-size:1rem">Subscribe</h5>

<form action="https://dev.us20.list-manage.com/subscribe/post?u=5212e33f7cd396dd4a742431c&amp;id=0a2f69f3f3&amp;f_id=002e29e8f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_self">

    <div class="form-group">
      <!-- <label for="mce-EMAIL" class="form-label mt-4">Subscribe via email</label> -->
      <input type="email" value="" name="EMAIL" class="form-control" id="mce-EMAIL" placeholder="enter your email" required="">
    </div>
    
    <div style="margin-top: 10px;">
    <button type="submit" class="btn btn-secondary btn-sm" data-umami-event="Subscribe">Submit</button>
    
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f718424fc5df77c22533bdaa6_a3c37fb57b" tabindex="-1" value=""></div>
    


<hr>
</div></form>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-xgboost-model-class" id="toc-the-xgboost-model-class" class="nav-link active" data-scroll-target="#the-xgboost-model-class">The XGBoost Model Class</a></li>
  <li><a href="#the-xgboost-tree-booster" id="toc-the-xgboost-tree-booster" class="nav-link" data-scroll-target="#the-xgboost-tree-booster">The XGBoost Tree Booster</a>
  <ul class="collapse">
  <li><a href="#initialization-and-inserting-child-nodes" id="toc-initialization-and-inserting-child-nodes" class="nav-link" data-scroll-target="#initialization-and-inserting-child-nodes">Initialization and Inserting Child Nodes</a></li>
  <li><a href="#split-finding" id="toc-split-finding" class="nav-link" data-scroll-target="#split-finding">Split Finding</a></li>
  <li><a href="#prediction" id="toc-prediction" class="nav-link" data-scroll-target="#prediction">Prediction</a></li>
  </ul></li>
  <li><a href="#the-complete-xgboost-from-scratch-implementation" id="toc-the-complete-xgboost-from-scratch-implementation" class="nav-link" data-scroll-target="#the-complete-xgboost-from-scratch-implementation">The Complete XGBoost From Scratch Implementation</a></li>
  <li><a href="#testing" id="toc-testing" class="nav-link" data-scroll-target="#testing">Testing</a></li>
  <li><a href="#wrapping-up" id="toc-wrapping-up" class="nav-link" data-scroll-target="#wrapping-up">Wrapping Up</a></li>
  <li><a href="#reader-exercises" id="toc-reader-exercises" class="nav-link" data-scroll-target="#reader-exercises">Reader Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">XGBoost from Scratch</h1>
  <div class="quarto-categories">
    <div class="quarto-category">python</div>
    <div class="quarto-category">gradient boosting</div>
    <div class="quarto-category">xgboost</div>
    <div class="quarto-category">from scratch</div>
  </div>
  </div>

<div>
  <div class="description">
    A walkthrough of my from-scratch python implementation of XGBoost.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Matt Bowers </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 7, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="main.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">A weathered tree reaches toward the sea at Playa Mal País</figcaption>
</figure>
</div>
<p>Well, dear reader, it’s that time again, time for us to do a seemingly unnecessary scratch build of a popular algorithm that most people would simply import from the library without a second thought. But readers of this blog are not most people. Of course you know that when we do scratch builds, it’s not for the hell of it, it’s for the purpose of demystification. To that end, today we are going to implement XGBoost from scratch in python, using only numpy and pandas.</p>
<p>Specifically we’re going to implement the core statistical learning algorithm of XGBoost, including most of the key hyperparameters and their functionality. Our implementation will also support user-defined custom objective functions, meaning that it can perform regression, classification, and whatever exotic learning tasks you can dream up, as long as you can write down a twice-differentiable objective function. We’ll refrain from implementing some simple features like column subsampling which will be left to you, gentle reader, as exercises. In terms of tree methods, we’re going to implement the exact tree-splitting algorithm, leaving the sparsity-aware method (used to handle missing feature values) and the approximate method (used for scalability) as exercises or maybe topics for future posts.</p>
<p>As always, if something is unclear, try backtracking through the previous posts on gradient boosting and decision trees to clarify your intuition. We’ve already built up all the statistical and computational background needed to make sense of this scratch build. Here are the most important prerequisite posts:</p>
<ol type="1">
<li><a href="../../posts/gradient-boosting-machine-from-scratch/">Gradient Boosting Machine from Scratch</a></li>
<li><a href="../../posts/decision-tree-from-scratch/">Decision Tree From Scratch</a></li>
<li><a href="../../posts/how-to-understand-xgboost/">How to Understand XGBoost</a></li>
</ol>
<p>Great, let’s do this.</p>
<section id="the-xgboost-model-class" class="level2">
<h2 class="anchored" data-anchor-id="the-xgboost-model-class">The XGBoost Model Class</h2>
<p>We begin with the user-facing API for our model, a class called <code>XGBoostModel</code> which will implement gradient boosting and prediction. To be more consistent with the XGBoost library, we’ll pass hyperparameters to our model in a parameter dictionary, so our init method is going to pull relevant parameters out of the dictionary and set them as object attributes. Note the use of python’s <code>defaultdict</code> so we don’t have to worry about handling key errors if we try to access a parameter that the user didn’t set in the dictionary.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XGBoostModel():</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''XGBoost from Scratch</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params, random_seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> defaultdict(<span class="kw">lambda</span>: <span class="va">None</span>, params)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.subsample <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'subsample'</span>] <span class="op">\</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'subsample'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'learning_rate'</span>] <span class="op">\</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'learning_rate'</span>] <span class="cf">else</span> <span class="fl">0.3</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_prediction <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'base_score'</span>] <span class="op">\</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'base_score'</span>] <span class="cf">else</span> <span class="fl">0.5</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_depth <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'max_depth'</span>] <span class="op">\</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'max_depth'</span>] <span class="cf">else</span> <span class="dv">5</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>random_seed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The fit method, based on our classic GBM, takes a feature dataframe, a target vector, the objective function, and the number of boosting rounds as arguments. The user-supplied objective function should be an object with loss, gradient, and hessian methods, each of which takes a target vector and a prediction vector as input; the loss method should return a scalar loss score, the gradient method should return a vector of gradients, and the hessian method should return a vector of hessians.</p>
<p>In contrast to boosting in the classic GBM, instead of computing residuals between the current predictions and the target, we compute gradients and hessians of the loss function with respect to the current predictions, and instead of predicting residuals with a decision tree, we fit a special XGBoost tree booster (which we’ll implement in a moment) using the gradients and hessians. I’ve also added row subsampling by drawing a random subset of instance indices and passing them to the tree booster during each boosting round. The rest of the fit method is the same as the classic GBM, and the predict method is identical too.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(<span class="va">self</span>, X, y, objective, num_boost_round, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    current_predictions <span class="op">=</span> <span class="va">self</span>.base_prediction <span class="op">*</span> np.ones(shape<span class="op">=</span>y.shape)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.boosters <span class="op">=</span> []</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_boost_round):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        gradients <span class="op">=</span> objective.gradient(y, current_predictions)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        hessians <span class="op">=</span> objective.hessian(y, current_predictions)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        sample_idxs <span class="op">=</span> <span class="va">None</span> <span class="cf">if</span> <span class="va">self</span>.subsample <span class="op">==</span> <span class="fl">1.0</span> <span class="op">\</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span> <span class="va">self</span>.rng.choice(<span class="bu">len</span>(y), </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                                 size<span class="op">=</span>math.floor(<span class="va">self</span>.subsample<span class="op">*</span><span class="bu">len</span>(y)), </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                                 replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        booster <span class="op">=</span> TreeBooster(X, gradients, hessians, </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                              <span class="va">self</span>.params, <span class="va">self</span>.max_depth, sample_idxs)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        current_predictions <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> booster.predict(X)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.boosters.append(booster)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose: </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">] train loss = </span><span class="sc">{</span>objective<span class="sc">.</span>loss(y, current_predictions)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="va">self</span>.base_prediction <span class="op">+</span> <span class="va">self</span>.learning_rate </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span> np.<span class="bu">sum</span>([booster.predict(X) <span class="cf">for</span> booster <span class="kw">in</span> <span class="va">self</span>.boosters], axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>XGBoostModel.fit <span class="op">=</span> fit</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>XGBoostModel.predict <span class="op">=</span> predict            </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>All we have to do now is implement the tree booster.</p>
</section>
<section id="the-xgboost-tree-booster" class="level2">
<h2 class="anchored" data-anchor-id="the-xgboost-tree-booster">The XGBoost Tree Booster</h2>
<p>The XGBoost tree booster is a modified version of the decision tree that we built in the decision tree from scratch post. Like the decision tree, we recursively build a binary tree structure by finding the best split rule for each node in the tree. The main difference is the criterion for evaluating splits and the way that we define a leaf’s predicted value. Instead of being functions of the target values of the instances in each node, the criterion and predicted values are functions of the instance gradients and hessians. Thus we need only make a couple of modifications to our previous decision tree implementation to create the XGBoost tree booster.</p>
<section id="initialization-and-inserting-child-nodes" class="level3">
<h3 class="anchored" data-anchor-id="initialization-and-inserting-child-nodes">Initialization and Inserting Child Nodes</h3>
<p>Most of the init method is just parsing the parameter dictionary to assign parameters as object attributes. The one notable difference from our decision tree is in the way we define the node’s predicted value. We define <code>self.value</code> according to equation 5 of the XGBoost paper, a simple function of the gradient and hessian values of the instances in the current node. Of course the init also goes on to build the tree via the maybe insert child nodes method. This method is nearly identical to the one we implemented for our decision tree. So far so good.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TreeBooster():</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, g, h, params, max_depth, idxs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> params</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_depth <span class="op">=</span> max_depth</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.max_depth <span class="op">&gt;=</span> <span class="dv">0</span>, <span class="st">'max_depth must be nonnegative'</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.min_child_weight <span class="op">=</span> params[<span class="st">'min_child_weight'</span>] <span class="op">\</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> params[<span class="st">'min_child_weight'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reg_lambda <span class="op">=</span> params[<span class="st">'reg_lambda'</span>] <span class="cf">if</span> params[<span class="st">'reg_lambda'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gamma <span class="op">=</span> params[<span class="st">'gamma'</span>] <span class="cf">if</span> params[<span class="st">'gamma'</span>] <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.colsample_bynode <span class="op">=</span> params[<span class="st">'colsample_bynode'</span>] <span class="op">\</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> params[<span class="st">'colsample_bynode'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(g, pd.Series): g <span class="op">=</span> g.values</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(h, pd.Series): h <span class="op">=</span> h.values</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idxs <span class="kw">is</span> <span class="va">None</span>: idxs <span class="op">=</span> np.arange(<span class="bu">len</span>(g))</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.idxs <span class="op">=</span> X, g, h, idxs</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n, <span class="va">self</span>.c <span class="op">=</span> <span class="bu">len</span>(idxs), X.shape[<span class="dv">1</span>]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> <span class="op">-</span>g[idxs].<span class="bu">sum</span>() <span class="op">/</span> (h[idxs].<span class="bu">sum</span>() <span class="op">+</span> <span class="va">self</span>.reg_lambda) <span class="co"># Eq (5)</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.best_score_so_far <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.max_depth <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._maybe_insert_child_nodes()</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _maybe_insert_child_nodes(<span class="va">self</span>):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.c): <span class="va">self</span>._find_better_split(i)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.is_leaf: <span class="cf">return</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.X.values[<span class="va">self</span>.idxs,<span class="va">self</span>.split_feature_idx]</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        left_idx <span class="op">=</span> np.nonzero(x <span class="op">&lt;=</span> <span class="va">self</span>.threshold)[<span class="dv">0</span>]</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        right_idx <span class="op">=</span> np.nonzero(x <span class="op">&gt;</span> <span class="va">self</span>.threshold)[<span class="dv">0</span>]</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.left <span class="op">=</span> TreeBooster(<span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.params, </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                                <span class="va">self</span>.max_depth <span class="op">-</span> <span class="dv">1</span>, <span class="va">self</span>.idxs[left_idx])</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.right <span class="op">=</span> TreeBooster(<span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.params, </span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                                 <span class="va">self</span>.max_depth <span class="op">-</span> <span class="dv">1</span>, <span class="va">self</span>.idxs[right_idx])</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> is_leaf(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.best_score_so_far <span class="op">==</span> <span class="fl">0.</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _find_better_split(<span class="va">self</span>, feature_idx):</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="split-finding" class="level3">
<h3 class="anchored" data-anchor-id="split-finding">Split Finding</h3>
<p>Split finding follows the exact same pattern that we used in the decision tree, except we keep track of gradient and hessian stats instead of target value stats, and of course we use the XGBoost gain criterion (equation 7 from the paper) for evaluating splits.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _find_better_split(<span class="va">self</span>, feature_idx):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.X.values[<span class="va">self</span>.idxs, feature_idx]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    g, h <span class="op">=</span> <span class="va">self</span>.g[<span class="va">self</span>.idxs], <span class="va">self</span>.h[<span class="va">self</span>.idxs]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    sort_idx <span class="op">=</span> np.argsort(x)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    sort_g, sort_h, sort_x <span class="op">=</span> g[sort_idx], h[sort_idx], x[sort_idx]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    sum_g, sum_h <span class="op">=</span> g.<span class="bu">sum</span>(), h.<span class="bu">sum</span>()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    sum_g_right, sum_h_right <span class="op">=</span> sum_g, sum_h</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    sum_g_left, sum_h_left <span class="op">=</span> <span class="fl">0.</span>, <span class="fl">0.</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="va">self</span>.n <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        g_i, h_i, x_i, x_i_next <span class="op">=</span> sort_g[i], sort_h[i], sort_x[i], sort_x[i <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        sum_g_left <span class="op">+=</span> g_i<span class="op">;</span> sum_g_right <span class="op">-=</span> g_i</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        sum_h_left <span class="op">+=</span> h_i<span class="op">;</span> sum_h_right <span class="op">-=</span> h_i</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sum_h_left <span class="op">&lt;</span> <span class="va">self</span>.min_child_weight <span class="kw">or</span> x_i <span class="op">==</span> x_i_next:<span class="cf">continue</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sum_h_right <span class="op">&lt;</span> <span class="va">self</span>.min_child_weight: <span class="cf">break</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        gain <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> ((sum_g_left<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h_left <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> (sum_g_right<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h_right <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>                        <span class="op">-</span> (sum_g<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                        ) <span class="op">-</span> <span class="va">self</span>.gamma<span class="op">/</span><span class="dv">2</span> <span class="co"># Eq(7) in the xgboost paper</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> gain <span class="op">&gt;</span> <span class="va">self</span>.best_score_so_far: </span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.split_feature_idx <span class="op">=</span> feature_idx</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_score_so_far <span class="op">=</span> gain</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.threshold <span class="op">=</span> (x_i <span class="op">+</span> x_i_next) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>TreeBooster._find_better_split <span class="op">=</span> _find_better_split</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="prediction" class="level3">
<h3 class="anchored" data-anchor-id="prediction">Prediction</h3>
<p>Prediction works exactly the same as in our decision tree, and the methods are nearly identical.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([<span class="va">self</span>._predict_row(row) <span class="cf">for</span> i, row <span class="kw">in</span> X.iterrows()])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _predict_row(<span class="va">self</span>, row):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.is_leaf: </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.value</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    child <span class="op">=</span> <span class="va">self</span>.left <span class="cf">if</span> row[<span class="va">self</span>.split_feature_idx] <span class="op">&lt;=</span> <span class="va">self</span>.threshold <span class="op">\</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span> <span class="va">self</span>.right</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> child._predict_row(row)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>TreeBooster.predict <span class="op">=</span> predict </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>TreeBooster._predict_row <span class="op">=</span> _predict_row </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="the-complete-xgboost-from-scratch-implementation" class="level2">
<h2 class="anchored" data-anchor-id="the-complete-xgboost-from-scratch-implementation">The Complete XGBoost From Scratch Implementation</h2>
<p>Here’s the entire implementation which produces a usable <code>XGBoostModel</code> class with fit and predict methods.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">class</span> XGBoostModel():</span>
<span id="cb7-2"><a href="#cb7-2"></a>    <span class="co">'''XGBoost from Scratch</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co">    '''</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    </span>
<span id="cb7-5"><a href="#cb7-5"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params, random_seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-6"><a href="#cb7-6"></a>        <span class="va">self</span>.params <span class="op">=</span> defaultdict(<span class="kw">lambda</span>: <span class="va">None</span>, params)</span>
<span id="cb7-7"><a href="#cb7-7"></a>        <span class="va">self</span>.subsample <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'subsample'</span>] <span class="op">\</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'subsample'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'learning_rate'</span>] <span class="op">\</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'learning_rate'</span>] <span class="cf">else</span> <span class="fl">0.3</span></span>
<span id="cb7-11"><a href="#cb7-11"></a>        <span class="va">self</span>.base_prediction <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'base_score'</span>] <span class="op">\</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'base_score'</span>] <span class="cf">else</span> <span class="fl">0.5</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>        <span class="va">self</span>.max_depth <span class="op">=</span> <span class="va">self</span>.params[<span class="st">'max_depth'</span>] <span class="op">\</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>            <span class="cf">if</span> <span class="va">self</span>.params[<span class="st">'max_depth'</span>] <span class="cf">else</span> <span class="dv">5</span></span>
<span id="cb7-15"><a href="#cb7-15"></a>        <span class="va">self</span>.rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>random_seed)</span>
<span id="cb7-16"><a href="#cb7-16"></a>                </span>
<span id="cb7-17"><a href="#cb7-17"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, objective, num_boost_round, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-18"><a href="#cb7-18"></a>        current_predictions <span class="op">=</span> <span class="va">self</span>.base_prediction <span class="op">*</span> np.ones(shape<span class="op">=</span>y.shape)</span>
<span id="cb7-19"><a href="#cb7-19"></a>        <span class="va">self</span>.boosters <span class="op">=</span> []</span>
<span id="cb7-20"><a href="#cb7-20"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_boost_round):</span>
<span id="cb7-21"><a href="#cb7-21"></a>            gradients <span class="op">=</span> objective.gradient(y, current_predictions)</span>
<span id="cb7-22"><a href="#cb7-22"></a>            hessians <span class="op">=</span> objective.hessian(y, current_predictions)</span>
<span id="cb7-23"><a href="#cb7-23"></a>            sample_idxs <span class="op">=</span> <span class="va">None</span> <span class="cf">if</span> <span class="va">self</span>.subsample <span class="op">==</span> <span class="fl">1.0</span> <span class="op">\</span></span>
<span id="cb7-24"><a href="#cb7-24"></a>                <span class="cf">else</span> <span class="va">self</span>.rng.choice(<span class="bu">len</span>(y), </span>
<span id="cb7-25"><a href="#cb7-25"></a>                                     size<span class="op">=</span>math.floor(<span class="va">self</span>.subsample<span class="op">*</span><span class="bu">len</span>(y)), </span>
<span id="cb7-26"><a href="#cb7-26"></a>                                     replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-27"><a href="#cb7-27"></a>            booster <span class="op">=</span> TreeBooster(X, gradients, hessians, </span>
<span id="cb7-28"><a href="#cb7-28"></a>                                  <span class="va">self</span>.params, <span class="va">self</span>.max_depth, sample_idxs)</span>
<span id="cb7-29"><a href="#cb7-29"></a>            current_predictions <span class="op">+=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> booster.predict(X)</span>
<span id="cb7-30"><a href="#cb7-30"></a>            <span class="va">self</span>.boosters.append(booster)</span>
<span id="cb7-31"><a href="#cb7-31"></a>            <span class="cf">if</span> verbose: </span>
<span id="cb7-32"><a href="#cb7-32"></a>                <span class="bu">print</span>(<span class="ss">f'[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">] train loss = </span><span class="sc">{</span>objective<span class="sc">.</span>loss(y, current_predictions)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb7-33"><a href="#cb7-33"></a>            </span>
<span id="cb7-34"><a href="#cb7-34"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb7-35"><a href="#cb7-35"></a>        <span class="cf">return</span> (<span class="va">self</span>.base_prediction <span class="op">+</span> <span class="va">self</span>.learning_rate </span>
<span id="cb7-36"><a href="#cb7-36"></a>                <span class="op">*</span> np.<span class="bu">sum</span>([booster.predict(X) <span class="cf">for</span> booster <span class="kw">in</span> <span class="va">self</span>.boosters], axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb7-37"><a href="#cb7-37"></a>    </span>
<span id="cb7-38"><a href="#cb7-38"></a><span class="kw">class</span> TreeBooster():</span>
<span id="cb7-39"><a href="#cb7-39"></a> </span>
<span id="cb7-40"><a href="#cb7-40"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, g, h, params, max_depth, idxs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-41"><a href="#cb7-41"></a>        <span class="va">self</span>.params <span class="op">=</span> params</span>
<span id="cb7-42"><a href="#cb7-42"></a>        <span class="va">self</span>.max_depth <span class="op">=</span> max_depth</span>
<span id="cb7-43"><a href="#cb7-43"></a>        <span class="cf">assert</span> <span class="va">self</span>.max_depth <span class="op">&gt;=</span> <span class="dv">0</span>, <span class="st">'max_depth must be nonnegative'</span></span>
<span id="cb7-44"><a href="#cb7-44"></a>        <span class="va">self</span>.min_child_weight <span class="op">=</span> params[<span class="st">'min_child_weight'</span>] <span class="op">\</span></span>
<span id="cb7-45"><a href="#cb7-45"></a>            <span class="cf">if</span> params[<span class="st">'min_child_weight'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb7-46"><a href="#cb7-46"></a>        <span class="va">self</span>.reg_lambda <span class="op">=</span> params[<span class="st">'reg_lambda'</span>] <span class="cf">if</span> params[<span class="st">'reg_lambda'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb7-47"><a href="#cb7-47"></a>        <span class="va">self</span>.gamma <span class="op">=</span> params[<span class="st">'gamma'</span>] <span class="cf">if</span> params[<span class="st">'gamma'</span>] <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb7-48"><a href="#cb7-48"></a>        <span class="va">self</span>.colsample_bynode <span class="op">=</span> params[<span class="st">'colsample_bynode'</span>] <span class="op">\</span></span>
<span id="cb7-49"><a href="#cb7-49"></a>            <span class="cf">if</span> params[<span class="st">'colsample_bynode'</span>] <span class="cf">else</span> <span class="fl">1.0</span></span>
<span id="cb7-50"><a href="#cb7-50"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(g, pd.Series): g <span class="op">=</span> g.values</span>
<span id="cb7-51"><a href="#cb7-51"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(h, pd.Series): h <span class="op">=</span> h.values</span>
<span id="cb7-52"><a href="#cb7-52"></a>        <span class="cf">if</span> idxs <span class="kw">is</span> <span class="va">None</span>: idxs <span class="op">=</span> np.arange(<span class="bu">len</span>(g))</span>
<span id="cb7-53"><a href="#cb7-53"></a>        <span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.idxs <span class="op">=</span> X, g, h, idxs</span>
<span id="cb7-54"><a href="#cb7-54"></a>        <span class="va">self</span>.n, <span class="va">self</span>.c <span class="op">=</span> <span class="bu">len</span>(idxs), X.shape[<span class="dv">1</span>]</span>
<span id="cb7-55"><a href="#cb7-55"></a>        <span class="va">self</span>.value <span class="op">=</span> <span class="op">-</span>g[idxs].<span class="bu">sum</span>() <span class="op">/</span> (h[idxs].<span class="bu">sum</span>() <span class="op">+</span> <span class="va">self</span>.reg_lambda) <span class="co"># Eq (5)</span></span>
<span id="cb7-56"><a href="#cb7-56"></a>        <span class="va">self</span>.best_score_so_far <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb7-57"><a href="#cb7-57"></a>        <span class="cf">if</span> <span class="va">self</span>.max_depth <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb7-58"><a href="#cb7-58"></a>            <span class="va">self</span>._maybe_insert_child_nodes()</span>
<span id="cb7-59"><a href="#cb7-59"></a></span>
<span id="cb7-60"><a href="#cb7-60"></a>    <span class="kw">def</span> _maybe_insert_child_nodes(<span class="va">self</span>):</span>
<span id="cb7-61"><a href="#cb7-61"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.c): <span class="va">self</span>._find_better_split(i)</span>
<span id="cb7-62"><a href="#cb7-62"></a>        <span class="cf">if</span> <span class="va">self</span>.is_leaf: <span class="cf">return</span></span>
<span id="cb7-63"><a href="#cb7-63"></a>        x <span class="op">=</span> <span class="va">self</span>.X.values[<span class="va">self</span>.idxs,<span class="va">self</span>.split_feature_idx]</span>
<span id="cb7-64"><a href="#cb7-64"></a>        left_idx <span class="op">=</span> np.nonzero(x <span class="op">&lt;=</span> <span class="va">self</span>.threshold)[<span class="dv">0</span>]</span>
<span id="cb7-65"><a href="#cb7-65"></a>        right_idx <span class="op">=</span> np.nonzero(x <span class="op">&gt;</span> <span class="va">self</span>.threshold)[<span class="dv">0</span>]</span>
<span id="cb7-66"><a href="#cb7-66"></a>        <span class="va">self</span>.left <span class="op">=</span> TreeBooster(<span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.params, </span>
<span id="cb7-67"><a href="#cb7-67"></a>                                <span class="va">self</span>.max_depth <span class="op">-</span> <span class="dv">1</span>, <span class="va">self</span>.idxs[left_idx])</span>
<span id="cb7-68"><a href="#cb7-68"></a>        <span class="va">self</span>.right <span class="op">=</span> TreeBooster(<span class="va">self</span>.X, <span class="va">self</span>.g, <span class="va">self</span>.h, <span class="va">self</span>.params, </span>
<span id="cb7-69"><a href="#cb7-69"></a>                                 <span class="va">self</span>.max_depth <span class="op">-</span> <span class="dv">1</span>, <span class="va">self</span>.idxs[right_idx])</span>
<span id="cb7-70"><a href="#cb7-70"></a></span>
<span id="cb7-71"><a href="#cb7-71"></a>    <span class="at">@property</span></span>
<span id="cb7-72"><a href="#cb7-72"></a>    <span class="kw">def</span> is_leaf(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.best_score_so_far <span class="op">==</span> <span class="fl">0.</span></span>
<span id="cb7-73"><a href="#cb7-73"></a>    </span>
<span id="cb7-74"><a href="#cb7-74"></a>    <span class="kw">def</span> _find_better_split(<span class="va">self</span>, feature_idx):</span>
<span id="cb7-75"><a href="#cb7-75"></a>        x <span class="op">=</span> <span class="va">self</span>.X.values[<span class="va">self</span>.idxs, feature_idx]</span>
<span id="cb7-76"><a href="#cb7-76"></a>        g, h <span class="op">=</span> <span class="va">self</span>.g[<span class="va">self</span>.idxs], <span class="va">self</span>.h[<span class="va">self</span>.idxs]</span>
<span id="cb7-77"><a href="#cb7-77"></a>        sort_idx <span class="op">=</span> np.argsort(x)</span>
<span id="cb7-78"><a href="#cb7-78"></a>        sort_g, sort_h, sort_x <span class="op">=</span> g[sort_idx], h[sort_idx], x[sort_idx]</span>
<span id="cb7-79"><a href="#cb7-79"></a>        sum_g, sum_h <span class="op">=</span> g.<span class="bu">sum</span>(), h.<span class="bu">sum</span>()</span>
<span id="cb7-80"><a href="#cb7-80"></a>        sum_g_right, sum_h_right <span class="op">=</span> sum_g, sum_h</span>
<span id="cb7-81"><a href="#cb7-81"></a>        sum_g_left, sum_h_left <span class="op">=</span> <span class="fl">0.</span>, <span class="fl">0.</span></span>
<span id="cb7-82"><a href="#cb7-82"></a></span>
<span id="cb7-83"><a href="#cb7-83"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="va">self</span>.n <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb7-84"><a href="#cb7-84"></a>            g_i, h_i, x_i, x_i_next <span class="op">=</span> sort_g[i], sort_h[i], sort_x[i], sort_x[i <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb7-85"><a href="#cb7-85"></a>            sum_g_left <span class="op">+=</span> g_i<span class="op">;</span> sum_g_right <span class="op">-=</span> g_i</span>
<span id="cb7-86"><a href="#cb7-86"></a>            sum_h_left <span class="op">+=</span> h_i<span class="op">;</span> sum_h_right <span class="op">-=</span> h_i</span>
<span id="cb7-87"><a href="#cb7-87"></a>            <span class="cf">if</span> sum_h_left <span class="op">&lt;</span> <span class="va">self</span>.min_child_weight <span class="kw">or</span> x_i <span class="op">==</span> x_i_next:<span class="cf">continue</span></span>
<span id="cb7-88"><a href="#cb7-88"></a>            <span class="cf">if</span> sum_h_right <span class="op">&lt;</span> <span class="va">self</span>.min_child_weight: <span class="cf">break</span></span>
<span id="cb7-89"><a href="#cb7-89"></a></span>
<span id="cb7-90"><a href="#cb7-90"></a>            gain <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> ((sum_g_left<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h_left <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb7-91"><a href="#cb7-91"></a>                            <span class="op">+</span> (sum_g_right<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h_right <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb7-92"><a href="#cb7-92"></a>                            <span class="op">-</span> (sum_g<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (sum_h <span class="op">+</span> <span class="va">self</span>.reg_lambda))</span>
<span id="cb7-93"><a href="#cb7-93"></a>                            ) <span class="op">-</span> <span class="va">self</span>.gamma<span class="op">/</span><span class="dv">2</span> <span class="co"># Eq(7) in the xgboost paper</span></span>
<span id="cb7-94"><a href="#cb7-94"></a>            <span class="cf">if</span> gain <span class="op">&gt;</span> <span class="va">self</span>.best_score_so_far: </span>
<span id="cb7-95"><a href="#cb7-95"></a>                <span class="va">self</span>.split_feature_idx <span class="op">=</span> feature_idx</span>
<span id="cb7-96"><a href="#cb7-96"></a>                <span class="va">self</span>.best_score_so_far <span class="op">=</span> gain</span>
<span id="cb7-97"><a href="#cb7-97"></a>                <span class="va">self</span>.threshold <span class="op">=</span> (x_i <span class="op">+</span> x_i_next) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb7-98"><a href="#cb7-98"></a>                </span>
<span id="cb7-99"><a href="#cb7-99"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb7-100"><a href="#cb7-100"></a>        <span class="cf">return</span> np.array([<span class="va">self</span>._predict_row(row) <span class="cf">for</span> i, row <span class="kw">in</span> X.iterrows()])</span>
<span id="cb7-101"><a href="#cb7-101"></a></span>
<span id="cb7-102"><a href="#cb7-102"></a>    <span class="kw">def</span> _predict_row(<span class="va">self</span>, row):</span>
<span id="cb7-103"><a href="#cb7-103"></a>        <span class="cf">if</span> <span class="va">self</span>.is_leaf: </span>
<span id="cb7-104"><a href="#cb7-104"></a>            <span class="cf">return</span> <span class="va">self</span>.value</span>
<span id="cb7-105"><a href="#cb7-105"></a>        child <span class="op">=</span> <span class="va">self</span>.left <span class="cf">if</span> row[<span class="va">self</span>.split_feature_idx] <span class="op">&lt;=</span> <span class="va">self</span>.threshold <span class="op">\</span></span>
<span id="cb7-106"><a href="#cb7-106"></a>            <span class="cf">else</span> <span class="va">self</span>.right</span>
<span id="cb7-107"><a href="#cb7-107"></a>        <span class="cf">return</span> child._predict_row(row)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="testing" class="level2">
<h2 class="anchored" data-anchor-id="testing">Testing</h2>
<p>Let’s take this baby for a spin and benchmark its performance against the actual XGBoost library. We use the scikit learn <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html">California housing dataset</a> for benchmarking.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> fetch_california_housing(as_frame<span class="op">=</span><span class="va">True</span>, return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                                                    random_state<span class="op">=</span><span class="dv">43</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s start with a nice friendly squared error objective function for training. We should probably have a future post all about how to define custom objective functions in XGBoost, but for now, here’s how I define squared error.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SquaredErrorObjective():</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loss(<span class="va">self</span>, y, pred): <span class="cf">return</span> np.mean((y <span class="op">-</span> pred)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> gradient(<span class="va">self</span>, y, pred): <span class="cf">return</span> pred <span class="op">-</span> y</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> hessian(<span class="va">self</span>, y, pred): <span class="cf">return</span> np.ones(<span class="bu">len</span>(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here I use a more or less arbitrary set of hyperparameters for training. Feel free to play around with tuning and trying other parameter combinations yourself.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: <span class="fl">0.1</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: <span class="dv">5</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: <span class="fl">0.8</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reg_lambda'</span>: <span class="fl">1.5</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gamma'</span>: <span class="fl">0.0</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_child_weight'</span>: <span class="dv">25</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'base_score'</span>: <span class="fl">0.0</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tree_method'</span>: <span class="st">'exact'</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>num_boost_round <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># train the from-scratch XGBoost model</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>model_scratch <span class="op">=</span> XGBoostModel(params, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>model_scratch.fit(X_train, y_train, SquaredErrorObjective(), num_boost_round)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># train the library XGBoost model</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(X_train, label<span class="op">=</span>y_train)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(X_test, label<span class="op">=</span>y_test)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>model_xgb <span class="op">=</span> xgb.train(params, dtrain, num_boost_round)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s check the models’ performance on the held out test data to benchmark our implementation.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>pred_scratch <span class="op">=</span> model_scratch.predict(X_test)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>pred_xgb <span class="op">=</span> model_xgb.predict(dtest)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'scratch score: </span><span class="sc">{</span>SquaredErrorObjective()<span class="sc">.</span>loss(y_test, pred_scratch)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'xgboost score: </span><span class="sc">{</span>SquaredErrorObjective()<span class="sc">.</span>loss(y_test, pred_xgb)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>scratch score: 0.2434125759558149
xgboost score: 0.24123239765807963</code></pre>
</div>
</div>
<p>Well, look at that! Our scratch-built SGBoost is looking pretty consistent with the library. Go us!</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>I’d say this is a pretty good milestone for us here at Random Realizations. We’ve been hammering away at the various concepts around gradient boosting, leaving a trail of equations and scratch-built algos in our wake. Today we put all of that together to create a legit scratch build of XGBoost, something that would have been out of reach for me before we embarked on this journey together over a year ago. To anyone with the patience to read through this stuff, cheers to you! I hope you’re learning and enjoying this as much as I am.</p>
</section>
<section id="reader-exercises" class="level2">
<h2 class="anchored" data-anchor-id="reader-exercises">Reader Exercises</h2>
<p>If you want to take this a step further and deepen your understanding and coding abilities, let me recommend some exercises for you.</p>
<ol type="1">
<li>Implement column subsampling. XGBoost itself provides column subsampling by tree, by level, and by node. Try implementing by tree first, then try adding by level or by node as well. These should be pretty straightforward to do.</li>
<li>Implement sparsity aware split finding for missing feature values (Algorithm 2 in the <a href="https://arxiv.org/abs/1603.02754">XGBoost paper</a>). This will be a little more involved, since you’ll need to refactor and modify several parts of the tree booster class.</li>
</ol>
</section>

</main> <!-- /main -->
<hr>

<!-- <div style="max-width: 80%;"> -->
<h3>Comments</h3>
<script data-isso="https://isso.randomrealizations.com/" src="https://isso.randomrealizations.com/js/embed.min.js">
</script>
<section id="isso-thread"></section>
<!-- </div> -->

<hr>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="mcb00/blog" issue-term="title" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>