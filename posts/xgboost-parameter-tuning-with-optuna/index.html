<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matt Bowers">
<meta name="dcterms.date" content="2023-12-18">
<meta name="description" content="My strategy for efficiently tuning XGBoost parameters with optuna">

<title>Random Realizations – Tuning XGBoost Parameters with Optuna</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" defer="" src="https://umami.randomrealizations.com/script.js" data-domains="randomrealizations.com" data-website-id="17844d61-f224-45c0-aa5f-2935c14dd5ac"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Random Realizations">
<meta property="og:description" content="A blog about data science, statistics, machine learning, and the scientific method">
<meta property="og:image" content="https://randomrealizations.com/posts/xgboost-parameter-tuning-with-optuna/opengraph.png">
<meta property="og:site-name" content="Random Realizations">
<meta property="og:image:alt" content="lunar halo">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Random Realizations</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html" rel="" target="">
 <span class="menu-text">Archive</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-series" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Series</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-series">    
        <li>
    <a class="dropdown-item" href="../../gradient-boosting-series.html" rel="" target="">
 <span class="dropdown-text">Gradient Boosting Series</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="https://python-bloggers.com/" rel="" target="">
 <span class="dropdown-text">Python-Bloggers</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/mcb00" rel="" title="Matt on Github" class="quarto-navigation-tool px-1" aria-label="Matt on Github"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/mcbwrs" rel="" title="Matt on Twitter" class="quarto-navigation-tool px-1" aria-label="Matt on Twitter"><i class="bi bi-twitter"></i></a>
    <a href="https://www.linkedin.com/in/matt-bowers" rel="" title="Matt on Linkedin" class="quarto-navigation-tool px-1" aria-label="Matt on Linkedin"><i class="bi bi-linkedin"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<h5 style="font-weight:600; font-size:1rem">Subscribe</h5>

<form action="https://dev.us20.list-manage.com/subscribe/post?u=5212e33f7cd396dd4a742431c&amp;id=0a2f69f3f3&amp;f_id=002e29e8f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_self">

    <div class="form-group">
      <!-- <label for="mce-EMAIL" class="form-label mt-4">Subscribe via email</label> -->
      <input type="email" value="" name="EMAIL" class="form-control" id="mce-EMAIL" placeholder="enter your email" required="">
    </div>
    
    <div style="margin-top: 10px;">
    <button type="submit" class="btn btn-secondary btn-sm" data-umami-event="Subscribe">Submit</button>
    
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f718424fc5df77c22533bdaa6_a3c37fb57b" tabindex="-1" value=""></div>
    


<hr>
</div></form>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#when-should-you-do-hyperparameter-tuning" id="toc-when-should-you-do-hyperparameter-tuning" class="nav-link active" data-scroll-target="#when-should-you-do-hyperparameter-tuning">When should you do hyperparameter tuning?</a></li>
  <li><a href="#xgboost-parameters" id="toc-xgboost-parameters" class="nav-link" data-scroll-target="#xgboost-parameters">XGBoost Parameters</a>
  <ul class="collapse">
  <li><a href="#tree-parameters" id="toc-tree-parameters" class="nav-link" data-scroll-target="#tree-parameters">Tree Parameters</a></li>
  <li><a href="#boosting-parameters" id="toc-boosting-parameters" class="nav-link" data-scroll-target="#boosting-parameters">Boosting Parameters</a></li>
  </ul></li>
  <li><a href="#an-efficient-parameter-search-strategy-for-xgboost" id="toc-an-efficient-parameter-search-strategy-for-xgboost" class="nav-link" data-scroll-target="#an-efficient-parameter-search-strategy-for-xgboost">An Efficient Parameter Search Strategy for XGBoost</a></li>
  <li><a href="#tuning-xgboost-parameters-with-optuna" id="toc-tuning-xgboost-parameters-with-optuna" class="nav-link" data-scroll-target="#tuning-xgboost-parameters-with-optuna">Tuning XGBoost Parameters with Optuna</a>
  <ul class="collapse">
  <li><a href="#example-tuning-the-bluebook-for-bulldozers-regression-model" id="toc-example-tuning-the-bluebook-for-bulldozers-regression-model" class="nav-link" data-scroll-target="#example-tuning-the-bluebook-for-bulldozers-regression-model">Example: Tuning the Bluebook for Bulldozers Regression Model</a></li>
  </ul></li>
  <li><a href="#preliminaries-base-parameters-and-scoring-function" id="toc-preliminaries-base-parameters-and-scoring-function" class="nav-link" data-scroll-target="#preliminaries-base-parameters-and-scoring-function">Preliminaries: base parameters and scoring function</a></li>
  <li><a href="#stage-1-tune-tree-parameters-with-optuna" id="toc-stage-1-tune-tree-parameters-with-optuna" class="nav-link" data-scroll-target="#stage-1-tune-tree-parameters-with-optuna">Stage 1: Tune Tree Parameters with Optuna</a></li>
  <li><a href="#stage-2-tune-boosting-parameters-with-early-stopping" id="toc-stage-2-tune-boosting-parameters-with-early-stopping" class="nav-link" data-scroll-target="#stage-2-tune-boosting-parameters-with-early-stopping">Stage 2: Tune Boosting Parameters with Early Stopping</a></li>
  <li><a href="#train-and-evaluate-the-final-model" id="toc-train-and-evaluate-the-final-model" class="nav-link" data-scroll-target="#train-and-evaluate-the-final-model">Train and Evaluate the Final Model</a></li>
  <li><a href="#wrapping-up" id="toc-wrapping-up" class="nav-link" data-scroll-target="#wrapping-up">Wrapping Up</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Tuning XGBoost Parameters with Optuna</h1>
  <div class="quarto-categories">
    <div class="quarto-category">python</div>
    <div class="quarto-category">tutorial</div>
    <div class="quarto-category">gradient boosting</div>
    <div class="quarto-category">xgboost</div>
  </div>
  </div>

<div>
  <div class="description">
    My strategy for efficiently tuning XGBoost parameters with optuna
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Matt Bowers </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 18, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Ahh, the dark art of hyperparameter tuning. It’s a key step in the machine learning workflow, and it’s an activity that can easily be overlooked or be overkill. Therefore, dear reader, it is an art that requires the application of both skill and wisdom to realize its full potential while avoiding its perils. Today I’ll show you my approach for hyperparameter tuning XGBoost, although the principles apply to any GBT framework. I’ll give you some intuition for how to think about the key parameters in XGBoost, and I’ll show you an efficient strategy for parameter tuning GBTs. I’ll be using the optuna python library to tune parameters with bayesian optimization, but you can implement my strategy with whatever hyperparameter tuning utility you like.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="optuna_main.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Lunar halo on a frosty night in Johnson City, TN</figcaption>
</figure>
</div>
<section id="when-should-you-do-hyperparameter-tuning" class="level2">
<h2 class="anchored" data-anchor-id="when-should-you-do-hyperparameter-tuning">When should you do hyperparameter tuning?</h2>
<p>Hyperparameter tuning can easily be overlooked in the move-fast-and-break-everything husstle of building an ML product, but it can also easily become overkill, depending on the application. There are two key questions to ask:</p>
<ol type="1">
<li>How much value is created by an incremental gain in model prediction accuracy?</li>
<li>What is the cost of increasing model prediction accuracy?</li>
</ol>
<p>The point is that sometimes a small gain in model prediction performance translates into millions of dollars of impact. The dream scenario is that you swoop in on some key model in your organization, markedly improve its accuracy with an easy afternoon of hyperparameter tuning, realize massive improvements in your org’s KPIs, and get mad respect, bonuses, and promoted. But the reality is that ofen additional model accuracy doesn’t really change business KPIs by very much. Try to figure out the actual value of improved model accuracy and proceed accordingly.</p>
<p>Remember too that hyperparameter tuning has its costs, most obviously the developer time and compute resources for the search itself. It can also lead us to deeper and deeper models which take longer to train, occupy larger memory footprints, and have higher prediction latency. Blindly chasing prediction accuracy can even backfire and make a system worse,e.g.&nbsp;by <a href="https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html#common-issues-with-propensity-score">degrading causal reasoning in decision-making systems</a>.</p>
<p>Moral of the story: think before you tune.</p>
</section>
<section id="xgboost-parameters" class="level2">
<h2 class="anchored" data-anchor-id="xgboost-parameters">XGBoost Parameters</h2>
<p>Gradient boosting algorithms like XGBoost have two main types of hyperparameters: <em>tree parameters</em> which control the decision tree trained at each boosting round and <em>boosting parameters</em> which control the boosting procedure itself. Below I’ll highlight my favorite parameters, but you can see the full list in the <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">documentation</a>.</p>
<section id="tree-parameters" class="level3">
<h3 class="anchored" data-anchor-id="tree-parameters">Tree Parameters</h3>
<p>In theory you can use any kind of model as a base learner in a gradient boosting algorithm, but for reasons we discussed before, <a href="../../posts/consider-the-decision-tree/">decision trees</a> are typically the best choice. In XGBoost, we can choose the tree construction algorithm, and we get three types of parameters to control its behavior: tree complexity parameters, sampling parameters, and regularization parameters.</p>
<section id="tree-construction-algorithm" class="level4">
<h4 class="anchored" data-anchor-id="tree-construction-algorithm">Tree construction algorithm</h4>
<p>The tree construction algorithm boils down to split finding, and different algorithms have different ways of generating candidate splits to consider. In XGBoost we have the parameter:</p>
<ul>
<li><code>tree_method</code> - select tree construction algorithm: <code>exact</code>, <code>hist</code>, or default <code>approx</code>. The exact method tends to be slow, so I usually consider approx and hist in parameter searches.</li>
</ul>
</section>
<section id="tree-complexity-parameters" class="level4">
<h4 class="anchored" data-anchor-id="tree-complexity-parameters">Tree complexity parameters</h4>
<p>Tree complexity just means how many leaf nodes the trees have, and therefore how expressive they can be. I use these two parameters:</p>
<ul>
<li><code>max_depth</code> - maximum number of split levels allowed. Reasonable values are usually from 3-12.</li>
<li><code>min_child_weight</code> - minimum allowable sum of hessian values over data in a node. When using mean squared error as the objective, this is the minimum number of samples allowed in a leaf node. In that case, values in [1, 200] usually work well.</li>
</ul>
<p>These two parameters oppose each other; increasing max depth allows for more expressive trees, while increasing min child weight makes trees less expressive and therefore is a powerful way to counter overfitting. Note that <code>gamma</code> (a.k.a. <code>min_split_loss</code>) also limits node splitting, but I usually don’t use it because <code>min_child_weight</code> seems to work well enough on its own.</p>
</section>
<section id="sampling-parameters" class="level4">
<h4 class="anchored" data-anchor-id="sampling-parameters">Sampling parameters</h4>
<p>XGBoost can randomly sample rows and columns to be used for training each tree; you might think of this as <em>bagging</em>. We have a few parameters:</p>
<ul>
<li><code>subsample</code> - proportion of rows to use in each tree. Setting this less than 1.0 results in stochastic gradient descent, because each tree is trained on only a subset of the entire training dataset. Any value in (0,1] is valid, but it seems like values in [0.7, 1] are usually the best.</li>
<li><code>colsample_bytree</code>, <code>colsample_bylevel</code>, <code>colsample_bynode</code> - control the fraction of columns available to each tree, at each split level, or at each split, respectively. I usually use either by level or by node because I like the idea that trees might be forced to learn interactions by having different features available at each subsequent split. Again, values in (0,1] are valid, but values in [0.5,1] usually seem to work best.</li>
</ul>
</section>
<section id="regularization-parameters" class="level4">
<h4 class="anchored" data-anchor-id="regularization-parameters">Regularization parameters</h4>
<p>In XGBoost, regularization penalizes the actual values predicted by the individual trees, pushing values toward zero. I usually use:</p>
<ul>
<li><code>reg_lambda</code> - L2 regularization of tree predicted values. Increasing this parameter decreases tree expressiveness and therefore counters overfitting. Valid values are in [0,<span class="math inline">\(\infty\)</span>), but good values typically fall in [1,10].</li>
</ul>
<p>There is also an L1 regularization parameter called <code>reg_alpha</code>; feel free to use it instead. It seems that using one or the other is usually sufficient.</p>
</section>
</section>
<section id="boosting-parameters" class="level3">
<h3 class="anchored" data-anchor-id="boosting-parameters">Boosting Parameters</h3>
<p>Trained gradient boosting models take the form:</p>
<p><span class="math display">\[ F(\mathbf{x}) = b + \eta \sum_{k=1}^{K} f_k(\mathbf{x}) \]</span></p>
<p>where <span class="math inline">\(b\)</span> is the constant base predicted value, <span class="math inline">\(f_k(\cdot)\)</span> is the base learner for round <span class="math inline">\(k\)</span>, parameter <span class="math inline">\(K\)</span> is the number of boosting rounds, and parameter <span class="math inline">\(\eta\)</span> is the learning rate. In XGBoost these parameters are controlled by:</p>
<ul>
<li><code>num_boost_round</code> - the number of boosting iterations.</li>
<li><code>learning_rate</code> - the scaling or “shrinkage” factor applied to the predicted value of each base learner. Valid values are in (0,1]; the default is 0.3.</li>
</ul>
<p>These two parameters are very closely linked; the optimal value of one depends on the value of the other, where smaller learning rates require more boosting rounds to reach optimality. While training a model with a given learning rate, accuracy tends to increase with additional boosting rounds up to a certain point, but beyond that point it flattens out or even gets worse. We can leverage this fact to make our tuning more efficient by using XGBoost’s <code>early_stopping_rounds: int</code> argument, which terminates training after observing the specified number of boosting rounds without any improvement to the evaluation metric on the validation set.</p>
</section>
</section>
<section id="an-efficient-parameter-search-strategy-for-xgboost" class="level2">
<h2 class="anchored" data-anchor-id="an-efficient-parameter-search-strategy-for-xgboost">An Efficient Parameter Search Strategy for XGBoost</h2>
<p>Efficiency is the key to effective parameter tuning, because wasting less time means searching more parameter values and finding better models in a given amount of time. Parameter search involves training models over and over, and what determines training time? Well given a training dataset and a tree construction algorithm, by far the most important parameter is the number of boosting rounds. So we want to avoid any unnecessary boosting rounds during parameter search.</p>
<p>Fortunately, the tree parameters tend to be independent of the boosting parameters, meaning that if we find a good combination of tree parameters, they will usually work well across various boosting parameter values. This insight leads to a strategy where I first simultaneously tune tree parameters and the learning rate while holding the boosting rounds fixed at a moderately small value for fast training. Then I can optionally train a model with optimal tree parameters and aggressive boosting parameters. Specifically, my strategy goes like this:</p>
<ol type="1">
<li>With early stopping enabled, fix the number of boosting rounds at a reasonable value, and perform a parameter search over all other relevant parameters. Note the best iteration of the best model found during the search.</li>
<li>Optionally, with early stopping enabled, train a new model using the optimal tree parameter values from stage 1, fix the learning rate at a very small value (<span class="math inline">\(\le 0.01\)</span>), and boost until early stopping is invoked.</li>
</ol>
<p>If using the one-stage procedure, train the final model using the optimal parameter values, and set the number of boosting rounds to the best iteration of the best model from the search. If using the second aggressive boosting step, train the final model using the optimal tree parameters from stage 1, the small learning rate you chose for stage 2, and the best boosting round from stage 2.</p>
</section>
<section id="tuning-xgboost-parameters-with-optuna" class="level2">
<h2 class="anchored" data-anchor-id="tuning-xgboost-parameters-with-optuna">Tuning XGBoost Parameters with Optuna</h2>
<p><a href="https://optuna.readthedocs.io/en/stable/">Optuna</a> is a model-agnostic python library for hyperparameter tuning. I like it because it has a flexible API that abstracts away the details of the search algorithm being used. That means you can use this one library to tune all kinds of different models, and you can easily switch the parameter sampling approach among grid search, random search, the very sensible default bayesian optimization, and more. Another massive benefit is that optuna provides a specific <a href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.XGBoostPruningCallback.html">XGBoost integration</a> which terminates training early on lousy parameter combinations.</p>
<p>You can install optuna with anaconda, e.g.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode .zsh code-with-copy"><code class="sourceCode zsh"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> conda install <span class="at">-c</span> conda-forge optuna</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="example-tuning-the-bluebook-for-bulldozers-regression-model" class="level3">
<h3 class="anchored" data-anchor-id="example-tuning-the-bluebook-for-bulldozers-regression-model">Example: Tuning the Bluebook for Bulldozers Regression Model</h3>
<p>To illustrate the procedure, we’ll tune the parameters for the regression model we built back in the <a href="../../posts/xgboost-for-regression-in-python/">XGBoost for regression</a> post. First we’ll load up the bulldozer data and prepare the features and target just like we did before.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'../xgboost-for-regression-in-python/Train.csv'</span>, parse_dates<span class="op">=</span>[<span class="st">'saledate'</span>])<span class="op">;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> encode_string_features(df):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    out_df <span class="op">=</span> df.copy()</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature, feature_type <span class="kw">in</span> df.dtypes.items():</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> feature_type <span class="op">==</span> <span class="st">'object'</span>:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            out_df[feature] <span class="op">=</span> out_df[feature].astype(<span class="st">'category'</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out_df</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> encode_string_features(df)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'saledate_days_since_epoch'</span>] <span class="op">=</span> (</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'saledate'</span>] <span class="op">-</span> pd.Timestamp(year<span class="op">=</span><span class="dv">1970</span>, month<span class="op">=</span><span class="dv">1</span>, day<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    ).dt.days</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'logSalePrice'</span>] <span class="op">=</span> np.log1p(df[<span class="st">'SalePrice'</span>])</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SalesID'</span>,</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MachineID'</span>,</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ModelID'</span>,</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'datasource'</span>,</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">'auctioneerID'</span>,</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'YearMade'</span>,</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MachineHoursCurrentMeter'</span>,</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'UsageBand'</span>,</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiModelDesc'</span>,</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiBaseModel'</span>,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiSecondaryDesc'</span>,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiModelSeries'</span>,</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiModelDescriptor'</span>,</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ProductSize'</span>,</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiProductClassDesc'</span>,</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">'state'</span>,</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ProductGroup'</span>,</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ProductGroupDesc'</span>,</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Drive_System'</span>,</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Enclosure'</span>,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Forks'</span>,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Pad_Type'</span>,</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Ride_Control'</span>,</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Stick'</span>,</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Transmission'</span>,</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Turbocharged'</span>,</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Blade_Extension'</span>,</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Blade_Width'</span>,</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Enclosure_Type'</span>,</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Engine_Horsepower'</span>,</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Hydraulics'</span>,</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Pushblock'</span>,</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Ripper'</span>,</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Scarifier'</span>,</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Tip_Control'</span>,</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Tire_Size'</span>,</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coupler'</span>,</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coupler_System'</span>,</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Grouser_Tracks'</span>,</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Hydraulics_Flow'</span>,</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Track_Type'</span>,</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Undercarriage_Pad_Width'</span>,</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Stick_Length'</span>,</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Thumb'</span>,</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Pattern_Changer'</span>,</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Grouser_Type'</span>,</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Backhoe_Mounting'</span>,</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Blade_Type'</span>,</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Travel_Controls'</span>,</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Differential_Type'</span>,</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Steering_Controls'</span>,</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    <span class="st">'saledate_days_since_epoch'</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a> ]</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'logSalePrice'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>But this time, since we’re going to slam our validation set over and over during hyperparameter search, we want to reserve an actual test set to check how the final model generalizes. We make four different <code>xgboost.DMatrix</code> datasets for this process: training, validation, training+validation, and test. Training and validation are for the parameter search, and training+validation and test are for the final model.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n_valid <span class="op">=</span> <span class="dv">12000</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>n_test <span class="op">=</span> <span class="dv">12000</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>sorted_df <span class="op">=</span> df.sort_values(by<span class="op">=</span><span class="st">'saledate'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> sorted_df[:<span class="op">-</span>(n_valid <span class="op">+</span> n_test)] </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>valid_df <span class="op">=</span> sorted_df[<span class="op">-</span>(n_valid <span class="op">+</span> n_test):<span class="op">-</span>n_test] </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> sorted_df[<span class="op">-</span>n_test:]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(data<span class="op">=</span>train_df[features], label<span class="op">=</span>train_df[target], </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                     enable_categorical<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>dvalid <span class="op">=</span> xgb.DMatrix(data<span class="op">=</span>valid_df[features], label<span class="op">=</span>valid_df[target], </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                     enable_categorical<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(data<span class="op">=</span>test_df[features], label<span class="op">=</span>test_df[target], </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>                    enable_categorical<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>dtrainvalid <span class="op">=</span> xgb.DMatrix(data<span class="op">=</span>pd.concat([train_df, valid_df])[features], </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>                          label<span class="op">=</span>pd.concat([train_df, valid_df])[target], </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>                          enable_categorical<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="preliminaries-base-parameters-and-scoring-function" class="level2">
<h2 class="anchored" data-anchor-id="preliminaries-base-parameters-and-scoring-function">Preliminaries: base parameters and scoring function</h2>
<p>There are a couple of parameters that we usually want to keep fixed across all trials in a parameter search, including the XGBoost objective for training and the evaluation metric to be used for early stopping. We’ll also want to implement a model scoring function that takes a trained model and a dataset and returns the score, in our case, RMSE.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>metric <span class="op">=</span> <span class="st">'rmse'</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>base_params <span class="op">=</span> {</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'objective'</span>: <span class="st">'reg:squarederror'</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'eval_metric'</span>: metric,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score_model(model, dmat):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> dmat.get_label() </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(dmat) </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mean_squared_error(y_true, y_pred, squared<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="stage-1-tune-tree-parameters-with-optuna" class="level2">
<h2 class="anchored" data-anchor-id="stage-1-tune-tree-parameters-with-optuna">Stage 1: Tune Tree Parameters with Optuna</h2>
<p>Next we implement our optuna objective, a function taking an optuna study <code>Trial</code> object and returning the score we want to optimize. We use the <code>suggest_categorical</code>, <code>suggest_float</code>, and <code>suggest_int</code> methods of the <code>Trial</code> object to define the search space for each parameter. Note the use of the pruning callback function which we pass into the <code>callback</code> argument of the XGBoost <code>train</code> function; this is a must, since it allows optuna to prune lousy models after a few boosting rounds. Then we train XGBoost using 500 boosting rounds, which takes only a few seconds on my little laptop. Finally we return the score as computed by our <code>model_score</code> function.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'tree_method'</span>: trial.suggest_categorical(<span class="st">'tree_method'</span>, [<span class="st">'approx'</span>, <span class="st">'hist'</span>]),</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'max_depth'</span>: trial.suggest_int(<span class="st">'max_depth'</span>, <span class="dv">3</span>, <span class="dv">12</span>),</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'min_child_weight'</span>: trial.suggest_int(<span class="st">'min_child_weight'</span>, <span class="dv">1</span>, <span class="dv">250</span>),</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'subsample'</span>: trial.suggest_float(<span class="st">'subsample'</span>, <span class="fl">0.1</span>, <span class="fl">01.0</span>),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'colsample_bynode'</span>: trial.suggest_float(<span class="st">'colsample_bynode'</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'reg_lambda'</span>: trial.suggest_float(<span class="st">'reg_lambda'</span>, <span class="fl">0.001</span>, <span class="dv">25</span>, log<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'learning_rate'</span>: trial.suggest_float(<span class="st">'learning_rate'</span>, <span class="fl">0.05</span>, <span class="fl">0.5</span>, log<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    num_boost_round <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    params.update(base_params)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    pruning_callback <span class="op">=</span> optuna.integration.XGBoostPruningCallback(trial, <span class="ss">f'valid-</span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> xgb.train(params<span class="op">=</span>params, dtrain<span class="op">=</span>dtrain, num_boost_round<span class="op">=</span>num_boost_round,</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                      evals<span class="op">=</span>[(dtrain, <span class="st">'train'</span>), (dvalid, <span class="st">'valid'</span>)],</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>                      early_stopping_rounds<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>                      verbose_eval<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>                      callbacks<span class="op">=</span>[pruning_callback])</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model.best_score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To create a new optuna study and search through 50 parameter combinations, you could just run these two lines.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'minimize'</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>But, in practice, I prefer to run these potentially long running tasks for a pre-specified amount of clock time, rather than a specified number of trials—who knows how long 50 trials will take. So, to run the optimization for around 600 seconds (long enough to go make a nice cup of tea, stretch, and come back), I do something like this:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'minimize'</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>tic <span class="op">=</span> time.time()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> time.time() <span class="op">-</span> tic <span class="op">&lt;</span> <span class="dv">600</span>:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    study.optimize(objective, n_trials<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Stage 1 =============================='</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'best score = </span><span class="sc">{</span>study<span class="sc">.</span>best_trial<span class="sc">.</span>value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'best params --------------------------'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> study.best_trial.params.items():</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(k, <span class="st">':'</span>, v)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stage 1 ==============================
best score = 0.22716975344231757
best params --------------------------
tree_method : hist
max_depth : 7
min_child_weight : 47
subsample : 0.644239586943823
colsample_bynode : 0.6324287447379262
reg_lambda : 0.008813955729768966
learning_rate : 0.12041680713201537</code></pre>
</div>
</div>
<p>If we are happy with this result, we can go ahead and train a final model on the training+validation set using these parameter values and our fixed number of boosting rounds. If we decide we want to tune the tree parameters a little more, we can just call <code>study.optimize(...)</code> again, adding as many trials as we want. Once we’re happy with the tree parameters, if we want more accuracy and are willing to accept longer training time and a bigger model, we can proceed to stage 2.</p>
</section>
<section id="stage-2-tune-boosting-parameters-with-early-stopping" class="level2">
<h2 class="anchored" data-anchor-id="stage-2-tune-boosting-parameters-with-early-stopping">Stage 2: Tune Boosting Parameters with Early Stopping</h2>
<p>Now we take the optimal tree parameters that we found in stage 1, and we train a new model with a fixed low learning rate—here I use 0.01, but you could go lower—and a large number of boosting rounds. The lower your learning rate, the better your performance (with diminishing returns) and the more boosting rounds you’ll need to max out the evaluation metric on the validation data.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {}</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>params.update(base_params)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>params.update(study.best_trial.params)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>params[<span class="st">'learning_rate'</span>] <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model_stage2 <span class="op">=</span> xgb.train(params<span class="op">=</span>params, dtrain<span class="op">=</span>dtrain, </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                         num_boost_round<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                         evals<span class="op">=</span>[(dtrain, <span class="st">'train'</span>), (dvalid, <span class="st">'valid'</span>)],</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                         early_stopping_rounds<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                         verbose_eval<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Stage 2 =============================='</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'best score = </span><span class="sc">{</span>score_model(model_stage2, dvalid)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>best_iteration <span class="op">=</span> model_stage2.best_iteration</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'best iteration = </span><span class="sc">{</span>best_iteration<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stage 2 ==============================
best score = 0.22271610796451569
best iteration = 6115</code></pre>
</div>
</div>
</section>
<section id="train-and-evaluate-the-final-model" class="level2">
<h2 class="anchored" data-anchor-id="train-and-evaluate-the-final-model">Train and Evaluate the Final Model</h2>
<p>Now we can train our final model on the combined training and validation datasets using the optimal tree parameters from stage 1 and the fixed learning rate and optimal boosting rounds from stage 2. Then we evaluate on the held out test data.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>params[<span class="st">'learning_rate'</span>] <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>model_final <span class="op">=</span> xgb.train(params<span class="op">=</span>params, dtrain<span class="op">=</span>dtrainvalid, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                        num_boost_round<span class="op">=</span>best_iteration,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                        evals<span class="op">=</span>[(dtrain, <span class="st">'train'</span>)],</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                        verbose_eval<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Final Model =========================='</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test score = </span><span class="sc">{</span>score_model(model_final, dtest)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'parameters ---------------------------'</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> params.items():</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(k, <span class="st">':'</span>, v)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'num_boost_round: </span><span class="sc">{</span>best_iteration<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Model ==========================
test score = 0.21926622092723846
parameters ---------------------------
objective : reg:squarederror
eval_metric : rmse
tree_method : hist
max_depth : 7
min_child_weight : 47
subsample : 0.644239586943823
colsample_bynode : 0.6324287447379262
reg_lambda : 0.008813955729768966
learning_rate : 0.01
num_boost_round: 6115</code></pre>
</div>
</div>
<p>Back in the <a href="../../posts/xgboost-for-regression-in-python/">regression post</a> we got an RMSE of about 0.231 just using default parameter values, which put us in about 5th place on the <a href="https://www.kaggle.com/competitions/bluebook-for-bulldozers/leaderboard">leaderboard for the Kagle dozers competition</a>. Now with less than 15 minutes of hyperparameter tuning, our RMSE is down to 0.219 which puts us in 1st place by a huge margin.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>There it is, an efficient and ridiculously easy hyperparameter tuning strategy for XGBoost using optuna. If you found this helpful, if you have questions, or if you have your own preferred method for parameter search, let me know about it down in the comments!</p>
</section>

</main> <!-- /main -->
<hr>

<!-- <div style="max-width: 80%;"> -->
<h3>Comments</h3>
<script data-isso="https://isso.randomrealizations.com/" src="https://isso.randomrealizations.com/js/embed.min.js">
</script>
<section id="isso-thread"></section>
<!-- </div> -->

<hr>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>