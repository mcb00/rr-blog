<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Random Realizations</title>
<link>https://randomrealizations.com/index.html</link>
<atom:link href="https://randomrealizations.com/index.xml" rel="self" type="application/rss+xml"/>
<description>A blog about data science, statistics, machine learning, and the scientific method</description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Tue, 01 Aug 2023 22:00:00 GMT</lastBuildDate>
<item>
  <title>Random Realizations Resurrected</title>
  <dc:creator>Matt Bowers</dc:creator>
  <link>https://randomrealizations.com/posts/random-realizations-resurrected/index.html</link>
  <description><![CDATA[ 



<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://randomrealizations.com/posts/random-realizations-resurrected/main.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Christ the Redeemer towers into a vast blue Brazilian sky.!</figcaption>
</figure>
</div>
<p>Well it’s been over a year since I posted anything here. You see, a lot has been going on here at the Random Realizations Remote Global Headquarters that has distracted from producing the high-quality data science content that you’re used to. Mostly I went on hiatus from work and started traveling, which turns out to be it’s own full time job. I had aspirations of writing more after leaving work, but of course, after leaving, I couldn’t be bothered to sit down at my laptop and type stuff about data science to yall. After all, life is bigger than that.</p>
<p>When I finally felt like opening up my laptop, I was confronted with an email from the maintainers of <a href="https://github.com/fastai/fastpages">fastpages</a>, the open source content management system (CMS) I originally used to create this blog, notifying me that the project was being deprecated and that I would need to migrate my content to some other platform.</p>
<p>Boo.</p>
<p>That didn’t sound like much fun, so I spent another few months ignoring the blog. But eventually, dear reader, I decided it was time to roll up my sleeves and get this blog thriving once again.</p>
<p>Ok so fastpages was going to be deprecated, and I needed to find a new CMS. My requirements were pretty simple: I wanted to write the blog posts with jupyter notebook, and I wanted to host the site on my own domain. Helpfully, the former maintainers of fastpages recommended an alternative CMS called <a href="https://quarto.org/">Quarto</a> which I had never heard of. Apparently I had been living under a rock because Quarto appears to be all the rage. Quarto’s website says it’s an open-source scientific and technical publishing system. I think it’s fair to think of it as a way to render plain text or source code from languages like python, R, and julia into a variety of different published formats like websites, books, or journal articles. It was developed by the good folks over at RStudio, and the project has a pretty active following over on <a href="https://github.com/quarto-dev">github</a>, so I think it’s less likely to suddenly disappear like fastpages.</p>
<p>So anyway, I’ve been migrating my content over into this new quarto universe.</p>
<p>You mayofficially consider this blog resurrected from the dead, because this is the first new post published after the migration. The site has a bit of a new look and feel, so I hope you like it. Do let me know in the comments if you find anything amiss with the new website. Otherwise we’ll just assume it’s fabulous.</p>
<p>I’m working on a post about how to create a blog with quarto using jupyter and python, so you can too!</p>
<p>See you in more posts real soon! Love, Matt.</p>
 ]]></description>
  <category>blogging</category>
  <guid>https://randomrealizations.com/posts/random-realizations-resurrected/index.html</guid>
  <pubDate>Tue, 01 Aug 2023 22:00:00 GMT</pubDate>
  <media:content url="https://randomrealizations.com/posts/random-realizations-resurrected/thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>XGBoost from Scratch</title>
  <dc:creator>Matt Bowers</dc:creator>
  <link>https://randomrealizations.com/posts/xgboost-from-scratch/index.html</link>
  <description><![CDATA[ 



<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://randomrealizations.com/posts/xgboost-from-scratch/main.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">A weathered tree reaches toward the sea at Playa Mal País</figcaption>
</figure>
</div>
<p>Well, dear reader, it’s that time again, time for us to do a seemingly unnecessary scratch build of a popular algorithm that most people would simply import from the library without a second thought. But readers of this blog are not most people. Of course you know that when we do scratch builds, it’s not for the hell of it, it’s for the purpose of demystification. To that end, today we are going to implement XGBoost from scratch in python, using only numpy and pandas.</p>
<p>Specifically we’re going to implement the core statistical learning algorithm of XGBoost, including most of the key hyperparameters and their functionality. Our implementation will also support user-defined custom objective functions, meaning that it can perform regression, classification, and whatever exotic learning tasks you can dream up, as long as you can write down a twice-differentiable objective function. We’ll refrain from implementing some simple features like column subsampling which will be left to you, gentle reader, as exercises. In terms of tree methods, we’re going to implement the exact tree-splitting algorithm, leaving the sparsity-aware method (used to handle missing feature values) and the approximate method (used for scalability) as exercises or maybe topics for future posts.</p>
<p>As always, if something is unclear, try backtracking through the previous posts on gradient boosting and decision trees to clarify your intuition. We’ve already built up all the statistical and computational background needed to make sense of this scratch build. Here are the most important prerequisite posts:</p>
<ol type="1">
<li><a href="../../posts/gradient-boosting-machine-from-scratch/">Gradient Boosting Machine from Scratch</a></li>
<li><a href="../../posts/decision-tree-from-scratch/">Decision Tree From Scratch</a></li>
<li><a href="../../posts/how-to-understand-xgboost/">How to Understand XGBoost</a></li>
</ol>
<p>Great, let’s do this.</p>
<section id="the-xgboost-model-class" class="level2">
<h2 class="anchored" data-anchor-id="the-xgboost-model-class">The XGBoost Model Class</h2>
<p>We begin with the user-facing API for our model, a class called <code>XGBoostModel</code> which will implement gradient boosting and prediction. To be more consistent with the XGBoost library, we’ll pass hyperparameters to our model in a parameter dictionary, so our init method is going to pull relevant parameters out of the dictionary and set them as object attributes. Note the use of python’s <code>defaultdict</code> so we don’t have to worry about handling key errors if we try to access a parameter that the user didn’t set in the dictionary.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np </span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> defaultdict</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> XGBoostModel():</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'''XGBoost from Scratch</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    '''</span></span>
<span id="cb2-4">    </span>
<span id="cb2-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, params, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb2-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> defaultdict(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, params)</span>
<span id="cb2-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb2-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span></span>
<span id="cb2-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'base_score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'base_score'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb2-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rng <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.default_rng(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>random_seed)</span></code></pre></div>
</div>
<p>The fit method, based on our classic GBM, takes a feature dataframe, a target vector, the objective function, and the number of boosting rounds as arguments. The user-supplied objective function should be an object with loss, gradient, and hessian methods, each of which takes a target vector and a prediction vector as input; the loss method should return a scalar loss score, the gradient method should return a vector of gradients, and the hessian method should return a vector of hessians.</p>
<p>In contrast to boosting in the classic GBM, instead of computing residuals between the current predictions and the target, we compute gradients and hessians of the loss function with respect to the current predictions, and instead of predicting residuals with a decision tree, we fit a special XGBoost tree booster (which we’ll implement in a moment) using the gradients and hessians. I’ve also added row subsampling by drawing a random subset of instance indices and passing them to the tree booster during each boosting round. The rest of the fit method is the same as the classic GBM, and the predict method is identical too.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y, objective, num_boost_round, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb3-2">    current_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.ones(shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y.shape)</span>
<span id="cb3-3">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(num_boost_round):</span>
<span id="cb3-5">        gradients <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> objective.gradient(y, current_predictions)</span>
<span id="cb3-6">        hessians <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> objective.hessian(y, current_predictions)</span>
<span id="cb3-7">        sample_idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb3-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rng.choice(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y), </span>
<span id="cb3-9">                                 size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>math.floor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)), </span>
<span id="cb3-10">                                 replace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb3-11">        booster <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(X, gradients, hessians, </span>
<span id="cb3-12">                              <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth, sample_idxs)</span>
<span id="cb3-13">        current_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> booster.predict(X)</span>
<span id="cb3-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters.append(booster)</span>
<span id="cb3-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> verbose: </span>
<span id="cb3-16">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'[</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">] train loss = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>objective<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>loss(y, current_predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb3-17">            </span>
<span id="cb3-18"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb3-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate </span>
<span id="cb3-20">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([booster.predict(X) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> booster <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb3-21"></span>
<span id="cb3-22">XGBoostModel.fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fit</span>
<span id="cb3-23">XGBoostModel.predict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predict            </span></code></pre></div>
</div>
<p>All we have to do now is implement the tree booster.</p>
</section>
<section id="the-xgboost-tree-booster" class="level2">
<h2 class="anchored" data-anchor-id="the-xgboost-tree-booster">The XGBoost Tree Booster</h2>
<p>The XGBoost tree booster is a modified version of the decision tree that we built in the decision tree from scratch post. Like the decision tree, we recursively build a binary tree structure by finding the best split rule for each node in the tree. The main difference is the criterion for evaluating splits and the way that we define a leaf’s predicted value. Instead of being functions of the target values of the instances in each node, the criterion and predicted values are functions of the instance gradients and hessians. Thus we need only make a couple of modifications to our previous decision tree implementation to create the XGBoost tree booster.</p>
<section id="initialization-and-inserting-child-nodes" class="level3">
<h3 class="anchored" data-anchor-id="initialization-and-inserting-child-nodes">Initialization and Inserting Child Nodes</h3>
<p>Most of the init method is just parsing the parameter dictionary to assign parameters as object attributes. The one notable difference from our decision tree is in the way we define the node’s predicted value. We define <code>self.value</code> according to equation 5 of the XGBoost paper, a simple function of the gradient and hessian values of the instances in the current node. Of course the init also goes on to build the tree via the maybe insert child nodes method. This method is nearly identical to the one we implemented for our decision tree. So far so good.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> TreeBooster():</span>
<span id="cb4-2"> </span>
<span id="cb4-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, g, h, params, max_depth, idxs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb4-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params</span>
<span id="cb4-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_depth</span>
<span id="cb4-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth must be nonnegative'</span></span>
<span id="cb4-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb4-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg_lambda'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg_lambda'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb4-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gamma'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gamma'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span></span>
<span id="cb4-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.colsample_bynode <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bynode'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bynode'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb4-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(g, pd.Series): g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g.values</span>
<span id="cb4-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(h, pd.Series): h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h.values</span>
<span id="cb4-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> idxs <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(g))</span>
<span id="cb4-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X, g, h, idxs</span>
<span id="cb4-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(idxs), X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb4-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>g[idxs].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (h[idxs].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Eq (5)</span></span>
<span id="cb4-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb4-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb4-21">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._maybe_insert_child_nodes()</span>
<span id="cb4-22"></span>
<span id="cb4-23">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _maybe_insert_child_nodes(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb4-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c): <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._find_better_split(i)</span>
<span id="cb4-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.is_leaf: <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span></span>
<span id="cb4-26">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X.values[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx]</span>
<span id="cb4-27">        left_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.nonzero(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-28">        right_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.nonzero(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-29">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, </span>
<span id="cb4-30">                                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs[left_idx])</span>
<span id="cb4-31">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, </span>
<span id="cb4-32">                                 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs[right_idx])</span>
<span id="cb4-33"></span>
<span id="cb4-34">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@property</span></span>
<span id="cb4-35">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> is_leaf(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>): <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb4-36"></span>
<span id="cb4-37">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _find_better_split(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, feature_idx):</span>
<span id="cb4-38">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">pass</span></span></code></pre></div>
</div>
</section>
<section id="split-finding" class="level3">
<h3 class="anchored" data-anchor-id="split-finding">Split Finding</h3>
<p>Split finding follows the exact same pattern that we used in the decision tree, except we keep track of gradient and hessian stats instead of target value stats, and of course we use the XGBoost gain criterion (equation 7 from the paper) for evaluating splits.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _find_better_split(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, feature_idx):</span>
<span id="cb5-2">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X.values[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs, feature_idx]</span>
<span id="cb5-3">    g, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs]</span>
<span id="cb5-4">    sort_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(x)</span>
<span id="cb5-5">    sort_g, sort_h, sort_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g[sort_idx], h[sort_idx], x[sort_idx]</span>
<span id="cb5-6">    sum_g, sum_h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(), h.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb5-7">    sum_g_right, sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sum_g, sum_h</span>
<span id="cb5-8">    sum_g_left, sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb5-9"></span>
<span id="cb5-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb5-11">        g_i, h_i, x_i, x_i_next <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sort_g[i], sort_h[i], sort_x[i], sort_x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb5-12">        sum_g_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> g_i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> sum_g_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> g_i</span>
<span id="cb5-13">        sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> h_i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> h_i</span>
<span id="cb5-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">or</span> x_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> x_i_next:<span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span></span>
<span id="cb5-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight: <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span>
<span id="cb5-16"></span>
<span id="cb5-17">        gain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ((sum_g_left<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb5-18">                        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (sum_g_right<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb5-19">                        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> (sum_g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb5-20">                        ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Eq(7) in the xgboost paper</span></span>
<span id="cb5-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> gain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far: </span>
<span id="cb5-22">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> feature_idx</span>
<span id="cb5-23">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gain</span>
<span id="cb5-24">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (x_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x_i_next) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb5-25">            </span>
<span id="cb5-26">TreeBooster._find_better_split <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _find_better_split</span></code></pre></div>
</div>
</section>
<section id="prediction" class="level3">
<h3 class="anchored" data-anchor-id="prediction">Prediction</h3>
<p>Prediction works exactly the same as in our decision tree, and the methods are nearly identical.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb6-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.array([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict_row(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, row <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> X.iterrows()])</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _predict_row(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, row):</span>
<span id="cb6-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.is_leaf: </span>
<span id="cb6-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value</span>
<span id="cb6-7">    child <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> row[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb6-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right</span>
<span id="cb6-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> child._predict_row(row)</span>
<span id="cb6-10"></span>
<span id="cb6-11">TreeBooster.predict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predict </span>
<span id="cb6-12">TreeBooster._predict_row <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _predict_row </span></code></pre></div>
</div>
</section>
</section>
<section id="the-complete-xgboost-from-scratch-implementation" class="level2">
<h2 class="anchored" data-anchor-id="the-complete-xgboost-from-scratch-implementation">The Complete XGBoost From Scratch Implementation</h2>
<p>Here’s the entire implementation which produces a usable <code>XGBoostModel</code> class with fit and predict methods.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> XGBoostModel():</span>
<span id="cb7-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'''XGBoost from Scratch</span></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    '''</span></span>
<span id="cb7-4">    </span>
<span id="cb7-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, params, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb7-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> defaultdict(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, params)</span>
<span id="cb7-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span></span>
<span id="cb7-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'base_score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'base_score'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb7-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb7-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rng <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.default_rng(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>random_seed)</span>
<span id="cb7-16">                </span>
<span id="cb7-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y, objective, num_boost_round, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb7-18">        current_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.ones(shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y.shape)</span>
<span id="cb7-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(num_boost_round):</span>
<span id="cb7-21">            gradients <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> objective.gradient(y, current_predictions)</span>
<span id="cb7-22">            hessians <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> objective.hessian(y, current_predictions)</span>
<span id="cb7-23">            sample_idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-24">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rng.choice(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y), </span>
<span id="cb7-25">                                     size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>math.floor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.subsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)), </span>
<span id="cb7-26">                                     replace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-27">            booster <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(X, gradients, hessians, </span>
<span id="cb7-28">                                  <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth, sample_idxs)</span>
<span id="cb7-29">            current_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> booster.predict(X)</span>
<span id="cb7-30">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters.append(booster)</span>
<span id="cb7-31">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> verbose: </span>
<span id="cb7-32">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'[</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">] train loss = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>objective<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>loss(y, current_predictions)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb7-33">            </span>
<span id="cb7-34">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb7-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.base_prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate </span>
<span id="cb7-36">                <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([booster.predict(X) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> booster <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.boosters], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb7-37">    </span>
<span id="cb7-38"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> TreeBooster():</span>
<span id="cb7-39"> </span>
<span id="cb7-40">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, g, h, params, max_depth, idxs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb7-41">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params</span>
<span id="cb7-42">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_depth</span>
<span id="cb7-43">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth must be nonnegative'</span></span>
<span id="cb7-44">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-45">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-46">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg_lambda'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg_lambda'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-47">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gamma'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gamma'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span></span>
<span id="cb7-48">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.colsample_bynode <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bynode'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-49">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bynode'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-50">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(g, pd.Series): g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g.values</span>
<span id="cb7-51">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(h, pd.Series): h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h.values</span>
<span id="cb7-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> idxs <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(g))</span>
<span id="cb7-53">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X, g, h, idxs</span>
<span id="cb7-54">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(idxs), X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb7-55">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>g[idxs].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (h[idxs].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Eq (5)</span></span>
<span id="cb7-56">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb7-57">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb7-58">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._maybe_insert_child_nodes()</span>
<span id="cb7-59"></span>
<span id="cb7-60">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _maybe_insert_child_nodes(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-61">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c): <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._find_better_split(i)</span>
<span id="cb7-62">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.is_leaf: <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span></span>
<span id="cb7-63">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X.values[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx]</span>
<span id="cb7-64">        left_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.nonzero(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-65">        right_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.nonzero(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-66">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, </span>
<span id="cb7-67">                                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs[left_idx])</span>
<span id="cb7-68">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TreeBooster(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.params, </span>
<span id="cb7-69">                                 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_depth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs[right_idx])</span>
<span id="cb7-70"></span>
<span id="cb7-71">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@property</span></span>
<span id="cb7-72">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> is_leaf(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>): <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb7-73">    </span>
<span id="cb7-74">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _find_better_split(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, feature_idx):</span>
<span id="cb7-75">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X.values[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs, feature_idx]</span>
<span id="cb7-76">        g, h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.g[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.h[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.idxs]</span>
<span id="cb7-77">        sort_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(x)</span>
<span id="cb7-78">        sort_g, sort_h, sort_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g[sort_idx], h[sort_idx], x[sort_idx]</span>
<span id="cb7-79">        sum_g, sum_h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> g.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(), h.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb7-80">        sum_g_right, sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sum_g, sum_h</span>
<span id="cb7-81">        sum_g_left, sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb7-82"></span>
<span id="cb7-83">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb7-84">            g_i, h_i, x_i, x_i_next <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sort_g[i], sort_h[i], sort_x[i], sort_x[i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb7-85">            sum_g_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> g_i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> sum_g_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> g_i</span>
<span id="cb7-86">            sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> h_i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> h_i</span>
<span id="cb7-87">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">or</span> x_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> x_i_next:<span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span></span>
<span id="cb7-88">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_child_weight: <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span>
<span id="cb7-89"></span>
<span id="cb7-90">            gain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> ((sum_g_left<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h_left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb7-91">                            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (sum_g_right<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h_right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb7-92">                            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> (sum_g<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sum_h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reg_lambda))</span>
<span id="cb7-93">                            ) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Eq(7) in the xgboost paper</span></span>
<span id="cb7-94">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> gain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far: </span>
<span id="cb7-95">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> feature_idx</span>
<span id="cb7-96">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.best_score_so_far <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gain</span>
<span id="cb7-97">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (x_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x_i_next) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb7-98">                </span>
<span id="cb7-99">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb7-100">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.array([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict_row(row) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, row <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> X.iterrows()])</span>
<span id="cb7-101"></span>
<span id="cb7-102">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _predict_row(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, row):</span>
<span id="cb7-103">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.is_leaf: </span>
<span id="cb7-104">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value</span>
<span id="cb7-105">        child <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.left <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> row[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.split_feature_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb7-106">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.right</span>
<span id="cb7-107">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> child._predict_row(row)</span></code></pre></div>
</div>
</section>
<section id="testing" class="level2">
<h2 class="anchored" data-anchor-id="testing">Testing</h2>
<p>Let’s take this baby for a spin and benchmark its performance against the actual XGBoost library. We use the scikit learn <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html">California housing dataset</a> for benchmarking.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> fetch_california_housing</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb8-3">    </span>
<span id="cb8-4">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fetch_california_housing(as_frame<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, return_X_y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb8-5">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, </span>
<span id="cb8-6">                                                    random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">43</span>)</span></code></pre></div>
</div>
<p>Let’s start with a nice friendly squared error objective function for training. We should probably have a future post all about how to define custom objective functions in XGBoost, but for now, here’s how I define squared error.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> SquaredErrorObjective():</span>
<span id="cb9-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> loss(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, y, pred): <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.mean((y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> gradient(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, y, pred): <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y</span>
<span id="cb9-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> hessian(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, y, pred): <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y))</span></code></pre></div>
</div>
<p>Here I use a more or less arbitrary set of hyperparameters for training. Feel free to play around with tuning and trying other parameter combinations yourself.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> xgb</span>
<span id="cb10-2"></span>
<span id="cb10-3">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb10-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb10-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb10-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>,</span>
<span id="cb10-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reg_lambda'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>,</span>
<span id="cb10-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gamma'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb10-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>,</span>
<span id="cb10-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'base_score'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb10-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tree_method'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'exact'</span>,</span>
<span id="cb10-12">}</span>
<span id="cb10-13">num_boost_round <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb10-14"></span>
<span id="cb10-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># train the from-scratch XGBoost model</span></span>
<span id="cb10-16">model_scratch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBoostModel(params, random_seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb10-17">model_scratch.fit(X_train, y_train, SquaredErrorObjective(), num_boost_round)</span>
<span id="cb10-18"></span>
<span id="cb10-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># train the library XGBoost model</span></span>
<span id="cb10-20">dtrain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.DMatrix(X_train, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train)</span>
<span id="cb10-21">dtest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.DMatrix(X_test, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_test)</span>
<span id="cb10-22">model_xgb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.train(params, dtrain, num_boost_round)</span></code></pre></div>
</div>
<p>Let’s check the models’ performance on the held out test data to benchmark our implementation.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">pred_scratch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_scratch.predict(X_test)</span>
<span id="cb11-2">pred_xgb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_xgb.predict(dtest)</span>
<span id="cb11-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'scratch score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>SquaredErrorObjective()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>loss(y_test, pred_scratch)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb11-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'xgboost score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>SquaredErrorObjective()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>loss(y_test, pred_xgb)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>scratch score: 0.2434125759558149
xgboost score: 0.24123239765807963</code></pre>
</div>
</div>
<p>Well, look at that! Our scratch-built SGBoost is looking pretty consistent with the library. Go us!</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>I’d say this is a pretty good milestone for us here at Random Realizations. We’ve been hammering away at the various concepts around gradient boosting, leaving a trail of equations and scratch-built algos in our wake. Today we put all of that together to create a legit scratch build of XGBoost, something that would have been out of reach for me before we embarked on this journey together over a year ago. To anyone with the patience to read through this stuff, cheers to you! I hope you’re learning and enjoying this as much as I am.</p>
</section>
<section id="reader-exercises" class="level2">
<h2 class="anchored" data-anchor-id="reader-exercises">Reader Exercises</h2>
<p>If you want to take this a step further and deepen your understanding and coding abilities, let me recommend some exercises for you.</p>
<ol type="1">
<li>Implement column subsampling. XGBoost itself provides column subsampling by tree, by level, and by node. Try implementing by tree first, then try adding by level or by node as well. These should be pretty straightforward to do.</li>
<li>Implement sparsity aware split finding for missing feature values (Algorithm 2 in the <a href="https://arxiv.org/abs/1603.02754">XGBoost paper</a>). This will be a little more involved, since you’ll need to refactor and modify several parts of the tree booster class.</li>
</ol>
</section>

 ]]></description>
  <category>gradient boosting</category>
  <category>from scratch</category>
  <guid>https://randomrealizations.com/posts/xgboost-from-scratch/index.html</guid>
  <pubDate>Fri, 06 May 2022 22:00:00 GMT</pubDate>
  <media:content url="https://randomrealizations.com/posts/xgboost-from-scratch/thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>XGBoost Explained</title>
  <dc:creator>Matt Bowers</dc:creator>
  <link>https://randomrealizations.com/posts/xgboost-explained/index.html</link>
  <description><![CDATA[ 



<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://randomrealizations.com/posts/xgboost-explained/main.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Tree branches on a chilly day in Johnson City</figcaption>
</figure>
</div>
<p>Ahh, XGBoost, what an absolutely stellar implementation of gradient boosting. Once Tianqi Chen and Carlos Guestrin of the University of Washington published the <a href="https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">XGBoost paper</a> and shared the <a href="https://github.com/dmlc/xgboost">open source code</a> in the mid 2010’s, the algorithm quickly gained adoption in the ML community, appearing in over half of winning Kagle submissions in 2015. Nowadays it’s certainly among the most popular gradient boosting libraries, along with LightGBM and CatBoost, although the highly scientific indicator of <a href="https://www.githubcompare.com/dmlc/xgboost+microsoft/lightgbm+catboost/catboost">GitHub stars per year</a> indicates that it is in fact the most beloved gradient boosting package of all. Since it was the first of the modern popular boosting frameworks, and since <a href="https://blog.dataiku.com/the-many-flavors-of-gradient-boosting-algorithms">benchmarking</a> indicates that no other boosting algorithm outperforms it, we can comfortably focus our attention on understanding XGBoost.</p>
<p>The XGBoost authors identify two key aspects of a machine learning system: (1) a flexible statistical model and (2) a scalable learning system to fit that model using data. XGBoost improves on both of these aspects, providing a more flexible and feature-rich statistical model and building a truly scalable system to fit it. In this post we’re going to focus on the statistical modeling innovations, outlining the key differences from the classic gradient boosting machine and divinginto the mathematical derivation of the XGBoost learning algorithm. If you’re not already familiar with <a href="../../posts/gradient-boosting-machine-from-scratch/">gradient boosting</a>, go back and read the earlier posts in the series before jumping in here.</p>
<p>Buckle up, dear reader. Today we understand how XGBoost works, no hand waving required.</p>
<section id="xgboost-is-a-gradient-boosting-machine" class="level2">
<h2 class="anchored" data-anchor-id="xgboost-is-a-gradient-boosting-machine">XGBoost is a Gradient Boosting Machine</h2>
<p>At a high level, XGBoost is an iteratively constructed composite model, just like the classic gradient boosting machine we discussed back in the <a href="../../posts/gradient-boosting-machine-from-scratch/">GBM post</a> . The final model takes the form</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i%20=%20F(%5Cmathbf%7Bx%7D_i)%20=%20b%20+%20%5Ceta%20%5Csum_%7Bk=1%7D%5EK%20f_k(%5Cmathbf%7Bx%7D_i)%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?b"> is the base prediction, <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate hyperparameter that helps control overfitting by reducing the contributions of each booster, and each of the <img src="https://latex.codecogs.com/png.latex?K"> boosters <img src="https://latex.codecogs.com/png.latex?f_k"> is a decision tree. To help us connect the dots between theory and code, whenever we encounter new hyperparameters, I’ll point out their names from the <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost Parameter Documentation</a>. So, <img src="https://latex.codecogs.com/png.latex?b"> can be set by <code>base_score</code>, and <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is set by either <code>eta</code> or <code>learning_rate</code>.</p>
<p>XGBoost introduces two key statistical learning improvements over the classic gradient boosting model. First, it reimagines the gradient descent algorithm used for training, and second it uses a custom-built decision tree with extra functionality as its booster. We’ll dive into each of these key innovations in the following sections.</p>
</section>
<section id="descent-algorithm-innovations" class="level2">
<h2 class="anchored" data-anchor-id="descent-algorithm-innovations">Descent Algorithm Innovations</h2>
<section id="regularized-objective-function" class="level3">
<h3 class="anchored" data-anchor-id="regularized-objective-function">Regularized Objective Function</h3>
<p>In the post on <a href="../../posts/gradient-boosting-machine-with-any-loss-function/">GBM with any loss function</a>, we looked at loss functions of the form <img src="https://latex.codecogs.com/png.latex?%5Csum_i%20l(y_i,%5Chat%7By%7D_i)"> which compute some distance between targets <img src="https://latex.codecogs.com/png.latex?y_i"> and predictions <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i"> and sum them up over the training dataset. XGBoost introduces regularization into the objective function so that the objective takes the form</p>
<p><img src="https://latex.codecogs.com/png.latex?%20L%20=%20%5Csum_i%20l(y_i,%5Chat%7By%7D_i)%20+%20%5Csum_k%20%5COmega(f_k)%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?l"> is some twice-differentiable loss function. <img src="https://latex.codecogs.com/png.latex?%5COmega"> is a regularization that penalizes the complexity of each tree booster, taking the form</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5COmega(f)%20=%20%5Cgamma%20T%20+%20%5Cfrac%7B1%7D%7B2%7D%20%5Clambda%20%7C%7Cw%7C%7C%5E2%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?T"> is the number of leaf nodes and <img src="https://latex.codecogs.com/png.latex?%7C%7Cw%7C%7C%5E2"> is the squared sum of the leaf prediction values. This introduces two new hyperparameters: <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> which penalizes the number of leaf nodes and <img src="https://latex.codecogs.com/png.latex?%5Clambda"> which is the L-2 regularization parameter for leaf predicted values. These are set by <code>gamma</code> and <code>reg_lambbda</code> in the XGBoost parametrization. Together, these provide powerful new controls to reduce overfitting due to overly complex tree boosters. Note that <img src="https://latex.codecogs.com/png.latex?%5Cgamma=%5Clambda=0"> reduces the objective back to an unregularized loss function as used in the classic GBM.</p>
</section>
<section id="an-aside-on-newtons-method" class="level3">
<h3 class="anchored" data-anchor-id="an-aside-on-newtons-method">An Aside on Newton’s Method</h3>
<p>As we’ll see soon, XGBoost uses <a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization">Newton’s Method</a> to minimize its objective function, so let’s start with a quick refresher.</p>
<p>Newton’s method is an iterative procedure for minimizing a function <img src="https://latex.codecogs.com/png.latex?s(x)">. At each step we have some input <img src="https://latex.codecogs.com/png.latex?x_t">, and our goal is to find a nudge value <img src="https://latex.codecogs.com/png.latex?u"> such that</p>
<p><img src="https://latex.codecogs.com/png.latex?%20s(x_t%20+%20u)%20%5Cle%20s(x_t)"></p>
<p>To find a good nudge value <img src="https://latex.codecogs.com/png.latex?u">, we generate a local quadratic approximation of the function in the neighborhood of the input <img src="https://latex.codecogs.com/png.latex?x_t">, and then we find the input value that would bring us to the minimum of the quadratic approximation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://randomrealizations.com/posts/xgboost-explained/newton.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Schematic of Newton’s method</figcaption>
</figure>
</div>
<p>The figure shows a single Newton step where we start at <img src="https://latex.codecogs.com/png.latex?x_t">, find the local quadratic approximation, and then jump a distance <img src="https://latex.codecogs.com/png.latex?u"> along the <img src="https://latex.codecogs.com/png.latex?x">-axis to land at the minimum of the quadratic. If we iterate in this way, we are likely to land close to the minimum of <img src="https://latex.codecogs.com/png.latex?s(x)">.</p>
<p>So how do we compute the quadratic approximation? We use the second order Taylor series expansion of <img src="https://latex.codecogs.com/png.latex?s(x)"> near the point <img src="https://latex.codecogs.com/png.latex?x_t">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20s(x_t%20+%20u)%20%5Capprox%20%20s(x_t)%20+%20s'(x_t)u%20+%20%5Cfrac%7B1%7D%7B2%7D%20s''(x_t)%20u%5E2%20"></p>
<p>To find the nudge value <img src="https://latex.codecogs.com/png.latex?u"> that minimizes the quadratic approximation, we can take the derivative with respect to <img src="https://latex.codecogs.com/png.latex?u">, set it to zero, and solve for <img src="https://latex.codecogs.com/png.latex?u">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%200%20=%20%5Cfrac%7Bd%7D%7Bdu%7D%20%20%5Cleft%20(%20s(x_t)%20+%20s'(x_t)u%20+%20%5Cfrac%7B1%7D%7B2%7D%20s''(x_t)%20u%5E2%20%5Cright%20)%20=%20s'(x_t)%20+%20s''(x_t)%20u%20"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Crightarrow%20u%5E*%20=%20-%5Cfrac%7Bs'(x_t)%7D%7Bs''(x_t)%7D%20"></p>
<p>And as long as <img src="https://latex.codecogs.com/png.latex?s''(x_t)%3E0"> (i.e., the parabola is pointing up), <img src="https://latex.codecogs.com/png.latex?s(x_t%20+%20u%5E*)%20%5Cle%20s(x_t)">.</p>
</section>
<section id="tree-boosting-with-newtons-method" class="level3">
<h3 class="anchored" data-anchor-id="tree-boosting-with-newtons-method">Tree Boosting with Newton’s Method</h3>
<p>This lands us at the heart of XGBoost, which uses Newton’s method, rather than gradient descent, to guide each round of boosting. This explanation will correspond very closely to section 2.2 of the XGBoost paper, but here I’ll explicitly spell out some of the intermediate steps which are omitted from their derivation, and you’ll get some additional commentary from me along the way.</p>
<section id="newton-descent-in-tree-space" class="level4">
<h4 class="anchored" data-anchor-id="newton-descent-in-tree-space">Newton Descent in Tree Space</h4>
<p>Suppose we’ve done <img src="https://latex.codecogs.com/png.latex?t-1"> boosting rounds, and we want to add the <img src="https://latex.codecogs.com/png.latex?t">-th booster to our composite model. Our current model’s prediction for instance <img src="https://latex.codecogs.com/png.latex?i"> is <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i%5E%7B(t-1)%7D">. If we add a new tree booster <img src="https://latex.codecogs.com/png.latex?f_t"> to our model, the objective function would give</p>
<p><img src="https://latex.codecogs.com/png.latex?%20L%5E%7B(t)%7D%20=%20%5Csum_%7Bi=1%7D%5En%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D%20+%20f_t(%5Cmathbf%7Bx%7D_i))%20+%20%5COmega(f_t)%20"></p>
<p>We need to choose <img src="https://latex.codecogs.com/png.latex?f_t"> so that it decreases the loss, i.e.&nbsp;we want</p>
<p><img src="https://latex.codecogs.com/png.latex?%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D%20+%20f_t(%5Cmathbf%7Bx%7D_i))%20%5Cle%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D)"></p>
<p>Does that sound familiar? In the previous section we used Newton’s method to find a value of <img src="https://latex.codecogs.com/png.latex?u"> that would make <img src="https://latex.codecogs.com/png.latex?s(x_t%20+%20u)%20%5Cle%20s(x_t)">. Let’s try the same thing with our loss function. To be explicit, the parallels are: <img src="https://latex.codecogs.com/png.latex?s(%5Ccdot)%20%5Crightarrow%20l(y_i,%20%5Ccdot)">, <img src="https://latex.codecogs.com/png.latex?x_t%20%5Crightarrow%20%5Chat%7By%7D_i%5E%7B(t-1)%7D">, and <img src="https://latex.codecogs.com/png.latex?u%20%5Crightarrow%20f_t(%5Cmathbf%7Bx%7D_i)">.</p>
<p>Let’s start by finding the second order Taylor series approximation for the loss around the point <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i%5E%7B(t-1)%7D">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D%20+%20f_t(%5Cmathbf%7Bx%7D_i))%20%5Capprox%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D)%20+%20g_i%20f_t(%5Cmathbf%7Bx%7D_i)%20+%20%5Cfrac%7B1%7D%7B2%7D%20h_i%20f_t(%5Cmathbf%7Bx%7D_i)%5E2%20"></p>
<p>where</p>
<p><img src="https://latex.codecogs.com/png.latex?%20g_i%20=%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Chat%7By%7D_i%5E%7B(t-1)%7D%7D%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D)"></p>
<p>and</p>
<p><img src="https://latex.codecogs.com/png.latex?%20h_i%20=%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%5E2%20%5Chat%7By%7D_i%5E%7B(t-1)%7D%7D%20l(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D)"></p>
<p>are the first and second order partial derivatives of the loss with respect to the current predictions. The XGBoost paper calls these the gradients and hessians, respectively. Remember that when we specify an actual loss function to use, we would also specify the functional form of the gradients and hessians, so that they are directly computable.</p>
<p>Now we can go back and substitute our quadratic approximation in for the loss function to get an approximation of the objective function in the neighborhood of <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i%5E%7B(t-1)%7D">..</p>
<p><img src="https://latex.codecogs.com/png.latex?%20L%5E%7B(t)%7D%20%5Capprox%20%5Csum_%7Bi=1%7D%5En%20%5Bl(y_i,%20%5Chat%7By%7D_i%5E%7B(t-1)%7D)%20+%20g_i%20f_t(%5Cmathbf%7Bx%7D_i)%20+%20%5Cfrac%7B1%7D%7B2%7D%20h_i%20f_t(%5Cmathbf%7Bx%7D_i)%5E2%5D%20+%20%5COmega(f_t)%20"></p>
<p>Since <img src="https://latex.codecogs.com/png.latex?l(y_i,%5Chat%7By%7D_i%5E%7B(t-1)%7D)"> is constant regardless of our choice of <img src="https://latex.codecogs.com/png.latex?f_t">, we can drop it and instead work with the modified objective, which gives us Equation (3) from the paper.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctilde%7BL%7D%5E%7B(t)%7D%20=%20%5Csum_%7Bi=1%7D%5En%20%5B%20g_i%20f_t(%5Cmathbf%7Bx%7D_i)%20+%20%5Cfrac%7B1%7D%7B2%7D%20h_i%20f_t(%5Cmathbf%7Bx%7D_i)%5E2%5D%20+%20%5COmega(f_t)%20"></p>
<p>Now the authors are about to do something great. They’re about to show how to directly compute the optimal prediction values for the leaf nodes of <img src="https://latex.codecogs.com/png.latex?f_t">. We’ll circle back in a moment about how we find a good structure for <img src="https://latex.codecogs.com/png.latex?f_t">, i.e.&nbsp;good node splits, but we’re going to find the optimal predicted values for any tree structure having <img src="https://latex.codecogs.com/png.latex?T"> terminal nodes. Let <img src="https://latex.codecogs.com/png.latex?I_j"> denote the set of instances <img src="https://latex.codecogs.com/png.latex?i"> that are in the <img src="https://latex.codecogs.com/png.latex?j">-th leaf node of <img src="https://latex.codecogs.com/png.latex?f_t">. Then we can rewrite the objective.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctilde%7BL%7D%5E%7B(t)%7D%20=%20%5Csum_%7Bj=1%7D%5ET%20%5Cleft%20%5B%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20f_t(%5Cmathbf%7Bx%7D_i)%20+%20%5Cfrac%7B1%7D%7B2%7D%20%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20f_t(%5Cmathbf%7Bx%7D_i)%5E2%20%5Cright%20%5D%20+%20%5COmega(f_t)"></p>
<p>We notice that for all instances in <img src="https://latex.codecogs.com/png.latex?I_j">, the tree yields the same predicted value <img src="https://latex.codecogs.com/png.latex?f_t(%5Cmathbf%7Bx%7D_i)=w_j">. Substituting in <img src="https://latex.codecogs.com/png.latex?w_j"> for the predicted values and expanding <img src="https://latex.codecogs.com/png.latex?%5COmega(f_t)"> we get</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctilde%7BL%7D%5E%7B(t)%7D%20=%20%5Csum_%7Bj=1%7D%5ET%20%5Cleft%20%5B%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20w_j%20+%20%5Cfrac%7B1%7D%7B2%7D%20%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20w_j%5E2%20%5Cright%20%5D%20+%20%5Cgamma%20T%20+%20%5Cfrac%7B1%7D%7B2%7D%20%5Clambda%20%5Csum_%7Bj=1%7D%5ET%20w_j%5E2"></p>
<p>Rearranging terms we obtain Equation (4).</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctilde%7BL%7D%5E%7B(t)%7D%20=%20%5Csum_%7Bj=1%7D%5ET%20%5Cleft%20%5B%20w_j%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20+%20%5Cfrac%7B1%7D%7B2%7D%20%20w_j%5E2%20%5Cleft%20(%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20+%20%5Clambda%20%5Cright%20)%20%20%5Cright%20%5D%20+%20%5Cgamma%20T%20"></p>
<p>For each leaf node <img src="https://latex.codecogs.com/png.latex?j">, our modified objective function is quadratic in <img src="https://latex.codecogs.com/png.latex?w_j">. To find the optimal predicted values we take the derivative, set to zero, and solve for <img src="https://latex.codecogs.com/png.latex?w_j">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%200%20=%20%5Cfrac%7Bd%7D%7Bdw_j%7D%20%5Cleft%20%5B%20w_j%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20+%20%5Cfrac%7B1%7D%7B2%7D%20%20w_j%5E2%20%5Cleft%20(%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20+%20%5Clambda%20%5Cright%20)%20%20%5Cright%20%5D%20=%20%5Cleft%20(%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20+%20%5Clambda%20%5Cright%20)%20w_j%20+%20%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20"></p>
<p>This yields Equation (5).</p>
<p><img src="https://latex.codecogs.com/png.latex?%20w_j%5E*%20=%20-%20%5Cfrac%7B%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20+%20%5Clambda%20%7D%20"></p>
</section>
<section id="split-finding" class="level4">
<h4 class="anchored" data-anchor-id="split-finding">Split Finding</h4>
<p>Now that we know how to find the optimal predicted value for any leaf node, we need to identify a criterion for finding a good tree structure, which boils down to finding the best split for a given node. Back in the [decision tree from scratch](/decision-tree-from-scratch post, we derived a split evaluation metric based on the reduction in the objective function associated with a particular split.<br>
To do that, first we need a way to compute the objective function given a particular tree structure. Substituting the optimal predicted values <img src="https://latex.codecogs.com/png.latex?w_j%5E*"> into the objective function, we get Equation (6).</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctilde%7BL%7D%5E%7B(t)%7D%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bj=1%7D%5ET%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I_j%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_j%7D%20h_i%20+%20%5Clambda%7D%20+%20%5Cgamma%20T%20"></p>
<p>We can then evaluate potential splits by comparing the objective before making a split to the objective after making a split, where the split with the maximum reduction in objective (a.k.a. gain) is best.</p>
<p>More formally, let <img src="https://latex.codecogs.com/png.latex?I"> be the set of <img src="https://latex.codecogs.com/png.latex?n"> data instances in the current node, and let <img src="https://latex.codecogs.com/png.latex?I_L"> and <img src="https://latex.codecogs.com/png.latex?I_R"> be the instances that fall into the left and right child nodes of a proposed split. Let <img src="https://latex.codecogs.com/png.latex?L"> be the total loss for all instances in the node, while <img src="https://latex.codecogs.com/png.latex?L_L"> and <img src="https://latex.codecogs.com/png.latex?L_R"> are the losses for the left and right child nodes. The total loss contributed by instances in node <img src="https://latex.codecogs.com/png.latex?I"> prior to any split is</p>
<p><img src="https://latex.codecogs.com/png.latex?L_%7B%5Ctext%7Bbefore%20split%7D%7D%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I%7D%20h_i%20+%20%5Clambda%7D%20+%20%5Cgamma%20"></p>
<p>And the loss after splitting <img src="https://latex.codecogs.com/png.latex?I"> into <img src="https://latex.codecogs.com/png.latex?I_L"> and <img src="https://latex.codecogs.com/png.latex?I_R"> is</p>
<p><img src="https://latex.codecogs.com/png.latex?L_%7B%5Ctext%7Bafter%20split%7D%7D%20=%20L_L%20+%20L_R%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I_L%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_L%7D%20h_i%20+%20%5Clambda%7D%20-%5Cfrac%7B1%7D%7B2%7D%20%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I_R%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_R%7D%20h_i%20+%20%5Clambda%7D%20+%202%20%5Cgamma%20"></p>
<p>The gain from this split is then</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5CDelta%20L%20=%20L_%7B%5Ctext%7Bbefore%20split%7D%7D%20-%20%20L_%7B%5Ctext%7Bafter%20split%7D%7D%20=%20L%20-%20(L_L%20+%20L_R)"> <img src="https://latex.codecogs.com/png.latex?%5CDelta%20L%20=%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%20%5B%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I_L%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_L%7D%20h_i%20+%20%5Clambda%7D%20+%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I_R%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I_R%7D%20h_i%20+%20%5Clambda%7D%20-%20%5Cfrac%7B%20(%5Csum_%7Bi%20%5Cin%20I%7D%20g_i%20)%5E2%20%7D%20%7B%5Csum_%7Bi%20%5Cin%20I%7D%20h_i%20+%20%5Clambda%7D%20%5Cright%20%5D%20-%20%5Cgamma%20"></p>
<p>which is Equation (7) from the paper. In practice it makes sense to accept a split only if the gain is positive, thus the <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> parameter sets the minimum gain required to make a further split. This is why <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> can be set with the parameter <code>gamma</code> or the more descriptive<code>min_loss_split</code>.</p>
</section>
</section>
</section>
<section id="tree-booster-innovations" class="level2">
<h2 class="anchored" data-anchor-id="tree-booster-innovations">Tree Booster Innovations</h2>
<section id="missing-values-and-sparsity-aware-split-finding" class="level3">
<h3 class="anchored" data-anchor-id="missing-values-and-sparsity-aware-split-finding">Missing Values and Sparsity-Aware Split Finding</h3>
<p>The XGBoost paper also introduces a modified algorithm for tree split finding which explicitly handles missing feature values. Recall that in order to find the best threshold value for a given feature, we can simply try all possible threshold values, recording the score for each. If some feature values are missing, the XGBoost split finding algorithm simply scores each threshold twice: once with missing value instances in the left node and once with them in the right node. The best split will then specify both the threshold value and to which node instances with missing values should be assigned. The paper calls this the sparsity aware split finding routine, which is defined as Algorithm 2.</p>
</section>
<section id="preventing-further-splitting" class="level3">
<h3 class="anchored" data-anchor-id="preventing-further-splitting">Preventing Further Splitting</h3>
<p>In addition to <code>min_loss_split</code> discussed above, XGBoost offers another parameter for limiting further tree splitting called <code>min_child_weight</code>. This name is a little confusing to me because the word “weight” has various meanings. In the context of this parameter, “weight” refers to the sum of the hessians <img src="https://latex.codecogs.com/png.latex?%5Csum%20h_i"> over instances in the node. For squared error loss <img src="https://latex.codecogs.com/png.latex?h_i=1">, so this is equivalent to the number of samples. Thus this parameter generalizes the notion of the minimum number of samples allowed in a terminal node.</p>
</section>
<section id="sampling" class="level3">
<h3 class="anchored" data-anchor-id="sampling">Sampling</h3>
<p>XGBoost takes a cue from Random Forest and introduces both column and row subsampling. These sampling methods can prevent overfitting and reduce training time by limiting the amount of data to be processed during boosting.</p>
<p>Like random forest, XGBoost implements column subsampling, which limits tree split finding to randomly selected subsets of features. XGBoost provides column sampling for each tree, for each depth level within a tree, and for each split point within a tree, controlled by <code>colsample_bytree</code>, <code>colsample_bbylevel</code>, and <code>colsample_bbynode</code> respectively.</p>
<p>One interesting distinction is that XGBoost implements row sampling without replacement using <code>subbsample</code>, whereas random forest uses bootstrapping. The choice to bootstrap rows in RF probably spurred from a desire to use as much data as possible while training on the smaller datasets of the 1990’s when RF was developed. With larger datasets and the ability to generate a large number of trees, XGBoost simply takes a subsample of rows for each tree.</p>
</section>
</section>
<section id="scalability" class="level2">
<h2 class="anchored" data-anchor-id="scalability">Scalability</h2>
<p>Even though we’re focused on statistical learning, I figured I’d comment on why XGBoost is highly scalable. Basically it boils down to efficient, parallelizable, and distributable methods for growing trees. You’ll notice there is a <code>tree_method</code> parameter which allows you to choose between the greedy exact algorithm (like the one we discussed in the decision tree from scratch post) and the approximate algorithm, which offers various scalability-related functionality, notably including the ability to consider only a small number of candidate split points instead of trying all possible splits. The algorithm also uses clever tricks like pre-sorting data for split finding and caching frequently needed values.</p>
<section id="why-xgboost-is-so-successful" class="level3">
<h3 class="anchored" data-anchor-id="why-xgboost-is-so-successful">Why XGBoost is so Successful</h3>
<p>As I mentioned in the intro, XGBoost is simply a very good implementation of the gradient boosting tree model. Therefore it inherits all the benefits of <a href="../../consider-the-decision-tree">decision trees and tree ensembles</a>, while making even further improvements over the classic gradient boosting machine. These improvements boil down to</p>
<ol type="1">
<li>more ways to control overfitting</li>
<li>elegant handling of custom objectives</li>
<li>scalability</li>
</ol>
<p>First, XGBoost introduces two new tree regularization hyperparameters <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda"> which are baked directly into its objective function. Combining these with the additional column and row sampling functionality provides a variety of ways to reduce overfitting.</p>
<p>Second, the XGBoost formulation provides a much more elegant way to train models on custom objective functions. Recall that for <a href="../../posts/gradient-boosting-machine-with-any-loss-function/">custom objectives</a>, the classic GBM finds tree structure by fitting a squared error decision tree to the gradients of the loss function and then sets each leaf’s predicted value by running a numerical optimization routine to find the optimal predicted value.</p>
<p>The XGBoost formulation improves on this two-stage approach by unifying the generation of tree structure and predicted values. Both the split scoring metric and the predicted values are directly computable from the instance gradient and hessian values, which are connected directly back to the overall training objective. This also removes the need for additional numerical optimizations, which contributes to speed, stability, and scalability.</p>
<p>Finally, speaking of scalability, XGBoost emerged at a time when industrial dataset size was exploding. Many use cases require scalable ML systems, and all use cases benefit from faster training and higher model development velocity.</p>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>Well, there you go, those are the salient ideas behind XGBoost, the gold standard in gradient boosting model implementations. Hopefully now we all understand the mathematical basis for the algorithm and appreciate the key improvements it makes over the classic GBM. If you want to go even deeper, you can join us for the next post where we’ll roll up our sleeves and implement XGBoost entirely from scratch.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p><a href="https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">The XGBoost paper</a></p>
</section>
<section id="exercise" class="level2">
<h2 class="anchored" data-anchor-id="exercise">Exercise</h2>
<p>Proove that the XGBoost Newton Descent generalizes the classic GBM gradient descent. Hint: show that XGBoost with a squared error objective and no regularization reduces to the classic GBM.</p>
</section>

 ]]></description>
  <category>gradient boosting</category>
  <guid>https://randomrealizations.com/posts/xgboost-explained/index.html</guid>
  <pubDate>Sat, 12 Mar 2022 22:00:00 GMT</pubDate>
  <media:content url="https://randomrealizations.com/posts/xgboost-explained/thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
